{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport gdown\nimport os\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\n# --- CONFIGURATION ---\nwarnings.filterwarnings('ignore')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 1. DOWNLOAD DATA\nfile_ids = {\n    'train_split.csv': '1IsyR3Xb_2cfvo457Fh8nE72VTifZb64W',\n    'val_split.csv': '1wX4PeKO6fPeLmICA2xmJ3gDUqv_MjE4B',\n    'test_split.csv': '1YSyXByVC105ifTZf-FX9IFjlAbZXbdSj',\n    'feature_columns.txt': '1PJqBlBZuxocIyHWywBhtaynUn2Pw-y5_'\n}\ndef download_from_drive(ids):\n    for filename, fid in ids.items():\n        if not os.path.exists(filename):\n            url = f'https://drive.google.com/uc?id={fid}'\n            gdown.download(url, filename, quiet=False)\n\ndownload_from_drive(file_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:02:55.576296Z","iopub.execute_input":"2026-02-21T12:02:55.576772Z","iopub.status.idle":"2026-02-21T12:03:15.275796Z","shell.execute_reply.started":"2026-02-21T12:02:55.576746Z","shell.execute_reply":"2026-02-21T12:03:15.274944Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1IsyR3Xb_2cfvo457Fh8nE72VTifZb64W\nFrom (redirected): https://drive.google.com/uc?id=1IsyR3Xb_2cfvo457Fh8nE72VTifZb64W&confirm=t&uuid=3d0f7aef-d2db-432f-9f20-9919059e050d\nTo: /kaggle/working/train_split.csv\n100%|██████████| 1.01G/1.01G [00:05<00:00, 181MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1wX4PeKO6fPeLmICA2xmJ3gDUqv_MjE4B\nFrom (redirected): https://drive.google.com/uc?id=1wX4PeKO6fPeLmICA2xmJ3gDUqv_MjE4B&confirm=t&uuid=852e772b-bc05-40b2-91a2-9cc1edc9aaaf\nTo: /kaggle/working/val_split.csv\n100%|██████████| 133M/133M [00:00<00:00, 157MB/s] \nDownloading...\nFrom (original): https://drive.google.com/uc?id=1YSyXByVC105ifTZf-FX9IFjlAbZXbdSj\nFrom (redirected): https://drive.google.com/uc?id=1YSyXByVC105ifTZf-FX9IFjlAbZXbdSj&confirm=t&uuid=d9ac363d-a302-4e67-be25-633f41f4167b\nTo: /kaggle/working/test_split.csv\n100%|██████████| 133M/133M [00:00<00:00, 204MB/s] \nDownloading...\nFrom: https://drive.google.com/uc?id=1PJqBlBZuxocIyHWywBhtaynUn2Pw-y5_\nTo: /kaggle/working/feature_columns.txt\n100%|██████████| 2.31k/2.31k [00:00<00:00, 6.67MB/s]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 2. DATA LOADING & PREPARATION\n# Load full data and sort by date to ensure temporal integrity\ndf_train = pd.read_csv('train_split.csv')\ndf_val = pd.read_csv('val_split.csv')\ndf = pd.concat([df_train, df_val], ignore_index=True)\n\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values('Date') \n\nwith open('feature_columns.txt', 'r') as f:\n    features = [line.strip() for line in f.readlines()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:03:31.752912Z","iopub.execute_input":"2026-02-21T12:03:31.753373Z","iopub.status.idle":"2026-02-21T12:03:49.556151Z","shell.execute_reply.started":"2026-02-21T12:03:31.753344Z","shell.execute_reply":"2026-02-21T12:03:49.555259Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# 3. SCRATCH LINEAR REGRESSION (CUDA)\nclass LinearRegressionScratch:\n    def fit(self, X, y):\n        # Adding bias term\n        ones = torch.ones((X.shape[0], 1), device=device)\n        X_b = torch.cat((ones, X), dim=1)\n        # Normal Equation using Pseudo-inverse for numerical stability\n        self.weights = torch.linalg.pinv(X_b.T @ X_b) @ X_b.T @ y\n        \n    def predict(self, X):\n        ones = torch.ones((X.shape[0], 1), device=device)\n        X_b = torch.cat((ones, X), dim=1)\n        # Clamp at 0 because sales cannot be negative\n        return torch.clamp(X_b @ self.weights, min=0)\n\n# 4. SCRATCH GRADIENT BOOSTED REGRESSOR (CUDA)\nclass GBDTScratch:\n    def __init__(self, n_estimators=10, max_depth=3, lr=0.1):\n        self.n_estimators = n_estimators\n        self.max_depth = max_depth\n        self.lr = lr\n        self.trees = []\n\n    def fit(self, X, y):\n        # Initial prediction (mean of target)\n        self.base_pred = torch.mean(y)\n        current_preds = torch.full_like(y, self.base_pred)\n\n        for i in range(self.n_estimators):\n            # Gradient Boosting: Predict the residuals (errors)\n            residuals = y - current_preds\n            \n            # Build tree on residuals\n            tree = self._build_tree(X, residuals, depth=0)\n            self.trees.append(tree)\n            \n            # Update overall predictions with learning rate\n            current_preds += self.lr * self._predict_tree(X, tree)\n            \n            # Requirement: Report RMSE at each boosting stage\n           \n            rmse = torch.sqrt(torch.mean((y - current_preds)**2))\n            print(f\"  > Boosting Round {i}, Residual RMSE: {rmse.item():.2f}\")\n\n    def _build_tree(self, X, res, depth):\n        if depth >= self.max_depth or len(res) < 10:\n            return torch.mean(res)\n\n        n_features = X.shape[1]\n        best_gain = -1\n        split_idx, split_val = 0, 0\n\n        # Optimization: Median-split on sampled features for speed\n        for f_idx in range(n_features):\n            feat_vals = X[:, f_idx]\n            threshold = torch.median(feat_vals)\n            \n            left_mask = feat_vals <= threshold\n            right_mask = ~left_mask\n            \n            if left_mask.sum() == 0 or right_mask.sum() == 0: continue\n            \n            # Variance Reduction Gain\n            gain = torch.var(res) - (left_mask.sum()*torch.var(res[left_mask]) + \n                                     right_mask.sum()*torch.var(res[right_mask])) / len(res)\n            \n            if gain > best_gain:\n                best_gain, split_idx, split_val = gain, f_idx, threshold\n\n        left_mask = X[:, split_idx] <= split_val\n        return {\n            'split_idx': split_idx,\n            'split_val': split_val,\n            'left': self._build_tree(X[left_mask], res[left_mask], depth+1),\n            'right': self._build_tree(X[~left_mask], res[~left_mask], depth+1)\n        }\n\n    def _predict_tree(self, X, tree):\n        if not isinstance(tree, dict):\n            return torch.full((X.shape[0],), tree, device=device)\n        \n        preds = torch.zeros(X.shape[0], device=device)\n        left_mask = X[:, tree['split_idx']] <= tree['split_val']\n        \n        preds[left_mask] = self._predict_tree(X[left_mask], tree['left'])\n        preds[~left_mask] = self._predict_tree(X[~left_mask], tree['right'])\n        return preds\n\n    def predict(self, X):\n        y_pred = torch.full((X.shape[0],), self.base_pred, device=device)\n        for tree in self.trees:\n            y_pred += self.lr * self._predict_tree(X, tree)\n        return torch.clamp(y_pred, min=0)\n\n# 5. EVALUATION: STORE-AWARE TEMPORAL CROSS-VALIDATION\ndef get_rmse(y_true, y_pred):\n    return torch.sqrt(torch.mean((y_true - y_pred)**2)).item()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:04:11.166810Z","iopub.execute_input":"2026-02-21T12:04:11.167195Z","iopub.status.idle":"2026-02-21T12:04:11.181560Z","shell.execute_reply.started":"2026-02-21T12:04:11.167169Z","shell.execute_reply":"2026-02-21T12:04:11.180898Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"for column in df[features].columns:\n    if df[column].dtype == 'object':\n        print(f\"Object Column Found: {column}\")\n        # Show a few unique values to see what the data looks like\n        print(f\"Sample values: {train_df[column].unique()[:5]}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:04:17.131684Z","iopub.execute_input":"2026-02-21T12:04:17.132346Z","iopub.status.idle":"2026-02-21T12:04:17.356625Z","shell.execute_reply.started":"2026-02-21T12:04:17.132317Z","shell.execute_reply":"2026-02-21T12:04:17.355943Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tscv = TimeSeriesSplit(n_splits=5)\nfold_results_lr = []\nfor fold, (train_idx, val_idx) in enumerate(tscv.split(df)):\n    print(f\"\\n--- FOLD {fold + 1} / 5 ---\")\n    \n    # Split data based on time-indices\n    train_fold = df.iloc[train_idx]\n    val_fold = df.iloc[val_idx]\n    # 1. Force all columns to numeric and cast the final array to float32\n    X_train_numeric = train_fold[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n    X_val_numeric = val_fold[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n    # 2. Now convert the pure float32 array to a Tensor\n    X_train = torch.tensor(X_train_numeric, device=device)\n    y_train = torch.tensor(train_fold['Sales'].values.astype(np.float32), device=device)\n    \n    X_val = torch.tensor(X_val_numeric, device=device)\n    y_val = torch.tensor(val_fold['Sales'].values.astype(np.float32), device=device)\n\n    # Train Scratch Linear Regression\n    lr_model = LinearRegressionScratch()\n    lr_model.fit(X_train, y_train)\n    lr_rmse = get_rmse(y_val, lr_model.predict(X_val))\n    fold_results_lr.append(lr_rmse)\n    \nprint(f\"Average Linear Regression RMSE: {np.mean(fold_results_lr):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T08:28:50.232292Z","iopub.execute_input":"2026-02-21T08:28:50.232584Z","iopub.status.idle":"2026-02-21T08:29:21.768452Z","shell.execute_reply.started":"2026-02-21T08:28:50.232553Z","shell.execute_reply":"2026-02-21T08:29:21.767808Z"}},"outputs":[{"name":"stdout","text":"\n--- FOLD 1 / 5 ---\n\n--- FOLD 2 / 5 ---\n\n--- FOLD 3 / 5 ---\n\n--- FOLD 4 / 5 ---\n\n--- FOLD 5 / 5 ---\nAverage Linear Regression RMSE: 752.02\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import itertools\n\n# 1. Define the Hyperparameter Grid\nparam_grid = {\n    'max_depth': [3, 4, 5, 10],\n    'lr': [0.05, 0.1],\n    'n_estimators':[5, 10]\n}\n\n# Generate all combinations\nkeys, values = zip(*param_grid.items())\npermutations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n\nbest_overall_rmse = float('inf')\nbest_config = None\n\nprint(f\"Starting Grid Search over {len(permutations)} combinations...\")\n\n# --- NEW OUTER LOOP FOR GRID SEARCH ---\nfor params in permutations:\n    print(f\"\\n\" + \"#\"*60)\n    print(f\"TESTING CONFIGURATION: {params}\")\n    print(\"#\"*60)\n\n    # Defining the Cross-Validation strategy\n    # This ensures we test on multiple future windows of the stores\n    tscv = TimeSeriesSplit(n_splits=5)\n    fold_results_gbdt = []\n\n    print(\"Starting Store-Aware Temporal Cross-Validation...\")\n\n    for fold, (train_idx, val_idx) in enumerate(tscv.split(df)):\n        print(f\"\\n--- FOLD {fold + 1} / 5 ---\")\n        \n        # Split data based on time-indices\n        train_fold = df.iloc[train_idx]\n        val_fold = df.iloc[val_idx]\n        \n        # 1. Force all columns to numeric and cast the final array to float32\n        X_train_numeric = train_fold[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n        X_val_numeric = val_fold[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n        # 2. Now convert the pure float32 array to a Tensor\n        X_train = torch.tensor(X_train_numeric, device=device)\n        y_train = torch.tensor(train_fold['Sales'].values.astype(np.float32), device=device)\n        \n        X_val = torch.tensor(X_val_numeric, device=device)\n        y_val = torch.tensor(val_fold['Sales'].values.astype(np.float32), device=device)\n\n        # Train Custom GBDT (Using parameters from Grid Search)\n        gbdt_model = GBDTScratch(n_estimators=params[\"n_estimators\"], max_depth=params['max_depth'], lr=params['lr'])\n        gbdt_model.fit(X_train, y_train)\n        gbdt_rmse = get_rmse(y_val, gbdt_model.predict(X_val))\n        fold_results_gbdt.append(gbdt_rmse)\n\n        print(f\"Fold Results -> LR RMSE: {lr_rmse:.2f} | GBDT RMSE: {gbdt_rmse:.2f}\")\n\n    # Calculate Average for this config\n    avg_gbdt_rmse = np.mean(fold_results_gbdt)\n    \n    # Track the best configuration\n    if avg_gbdt_rmse < best_overall_rmse:\n        best_overall_rmse = avg_gbdt_rmse\n        best_config = params\n\n    # 6. SUMMARY FOR CURRENT CONFIGURATION\n    print(\"\\n\" + \"=\"*40)\n    print(f\"SUMMARY FOR CONFIG: {params}\")\n    print(\"=\"*40)\n    print(f\"Average Custom GBDT RMSE: {avg_gbdt_rmse:.2f}\")\n    print(\"=\"*40)\n\n# FINAL GLOBAL RESULT\nprint(\"\\n\\n\" + \"!\"*60)\nprint(f\"GRID SEARCH COMPLETE\")\nprint(f\"BEST CONFIGURATION For gdb: {best_config}\")\nprint(f\"LOWEST AVERAGE CV RMSE: {best_overall_rmse:.2f}\")\nprint(\"!\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T08:29:21.769272Z","iopub.execute_input":"2026-02-21T08:29:21.769544Z","iopub.status.idle":"2026-02-21T10:52:27.441629Z","shell.execute_reply.started":"2026-02-21T08:29:21.769522Z","shell.execute_reply":"2026-02-21T10:52:27.440957Z"}},"outputs":[{"name":"stdout","text":"Starting Grid Search over 16 combinations...\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 3, 'lr': 0.05, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3594.27\n  > Boosting Round 1, Residual RMSE: 3452.72\n  > Boosting Round 2, Residual RMSE: 3319.41\n  > Boosting Round 3, Residual RMSE: 3194.08\n  > Boosting Round 4, Residual RMSE: 3075.77\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2974.50\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3531.00\n  > Boosting Round 1, Residual RMSE: 3392.42\n  > Boosting Round 2, Residual RMSE: 3262.19\n  > Boosting Round 3, Residual RMSE: 3139.62\n  > Boosting Round 4, Residual RMSE: 3024.36\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3396.66\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3659.28\n  > Boosting Round 1, Residual RMSE: 3516.12\n  > Boosting Round 2, Residual RMSE: 3381.16\n  > Boosting Round 3, Residual RMSE: 3254.50\n  > Boosting Round 4, Residual RMSE: 3135.22\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3129.71\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3661.51\n  > Boosting Round 1, Residual RMSE: 3517.48\n  > Boosting Round 2, Residual RMSE: 3382.32\n  > Boosting Round 3, Residual RMSE: 3254.49\n  > Boosting Round 4, Residual RMSE: 3134.62\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3024.79\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3638.57\n  > Boosting Round 1, Residual RMSE: 3495.80\n  > Boosting Round 2, Residual RMSE: 3360.73\n  > Boosting Round 3, Residual RMSE: 3233.72\n  > Boosting Round 4, Residual RMSE: 3114.64\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3412.66\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 3, 'lr': 0.05, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 3187.66\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 3, 'lr': 0.05, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3594.27\n  > Boosting Round 1, Residual RMSE: 3452.72\n  > Boosting Round 2, Residual RMSE: 3319.41\n  > Boosting Round 3, Residual RMSE: 3194.08\n  > Boosting Round 4, Residual RMSE: 3075.77\n  > Boosting Round 5, Residual RMSE: 2964.86\n  > Boosting Round 6, Residual RMSE: 2860.58\n  > Boosting Round 7, Residual RMSE: 2763.01\n  > Boosting Round 8, Residual RMSE: 2671.24\n  > Boosting Round 9, Residual RMSE: 2585.62\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2506.64\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3531.00\n  > Boosting Round 1, Residual RMSE: 3392.42\n  > Boosting Round 2, Residual RMSE: 3262.19\n  > Boosting Round 3, Residual RMSE: 3139.62\n  > Boosting Round 4, Residual RMSE: 3024.36\n  > Boosting Round 5, Residual RMSE: 2915.01\n  > Boosting Round 6, Residual RMSE: 2812.81\n  > Boosting Round 7, Residual RMSE: 2716.24\n  > Boosting Round 8, Residual RMSE: 2625.75\n  > Boosting Round 9, Residual RMSE: 2540.38\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2897.82\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3659.28\n  > Boosting Round 1, Residual RMSE: 3516.12\n  > Boosting Round 2, Residual RMSE: 3381.16\n  > Boosting Round 3, Residual RMSE: 3254.50\n  > Boosting Round 4, Residual RMSE: 3135.22\n  > Boosting Round 5, Residual RMSE: 3022.82\n  > Boosting Round 6, Residual RMSE: 2916.98\n  > Boosting Round 7, Residual RMSE: 2817.77\n  > Boosting Round 8, Residual RMSE: 2724.07\n  > Boosting Round 9, Residual RMSE: 2636.54\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2616.42\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3661.51\n  > Boosting Round 1, Residual RMSE: 3517.48\n  > Boosting Round 2, Residual RMSE: 3382.32\n  > Boosting Round 3, Residual RMSE: 3254.49\n  > Boosting Round 4, Residual RMSE: 3134.62\n  > Boosting Round 5, Residual RMSE: 3021.34\n  > Boosting Round 6, Residual RMSE: 2915.25\n  > Boosting Round 7, Residual RMSE: 2815.00\n  > Boosting Round 8, Residual RMSE: 2720.64\n  > Boosting Round 9, Residual RMSE: 2632.66\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2531.41\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3638.57\n  > Boosting Round 1, Residual RMSE: 3495.80\n  > Boosting Round 2, Residual RMSE: 3360.73\n  > Boosting Round 3, Residual RMSE: 3233.72\n  > Boosting Round 4, Residual RMSE: 3114.64\n  > Boosting Round 5, Residual RMSE: 3002.03\n  > Boosting Round 6, Residual RMSE: 2896.63\n  > Boosting Round 7, Residual RMSE: 2796.95\n  > Boosting Round 8, Residual RMSE: 2703.83\n  > Boosting Round 9, Residual RMSE: 2615.94\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2898.20\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 3, 'lr': 0.05, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2690.10\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 3, 'lr': 0.1, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3445.38\n  > Boosting Round 1, Residual RMSE: 3181.16\n  > Boosting Round 2, Residual RMSE: 2948.39\n  > Boosting Round 3, Residual RMSE: 2742.82\n  > Boosting Round 4, Residual RMSE: 2563.99\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2486.26\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3385.62\n  > Boosting Round 1, Residual RMSE: 3126.81\n  > Boosting Round 2, Residual RMSE: 2899.49\n  > Boosting Round 3, Residual RMSE: 2696.58\n  > Boosting Round 4, Residual RMSE: 2519.61\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2876.26\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3508.64\n  > Boosting Round 1, Residual RMSE: 3241.30\n  > Boosting Round 2, Residual RMSE: 3005.54\n  > Boosting Round 3, Residual RMSE: 2797.18\n  > Boosting Round 4, Residual RMSE: 2613.85\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2594.15\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3509.95\n  > Boosting Round 1, Residual RMSE: 3242.22\n  > Boosting Round 2, Residual RMSE: 3004.58\n  > Boosting Round 3, Residual RMSE: 2795.43\n  > Boosting Round 4, Residual RMSE: 2610.72\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2508.68\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3487.87\n  > Boosting Round 1, Residual RMSE: 3221.17\n  > Boosting Round 2, Residual RMSE: 2985.08\n  > Boosting Round 3, Residual RMSE: 2777.23\n  > Boosting Round 4, Residual RMSE: 2593.52\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2876.60\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 3, 'lr': 0.1, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 2668.39\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 3, 'lr': 0.1, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3445.38\n  > Boosting Round 1, Residual RMSE: 3181.16\n  > Boosting Round 2, Residual RMSE: 2948.39\n  > Boosting Round 3, Residual RMSE: 2742.82\n  > Boosting Round 4, Residual RMSE: 2563.99\n  > Boosting Round 5, Residual RMSE: 2408.00\n  > Boosting Round 6, Residual RMSE: 2269.41\n  > Boosting Round 7, Residual RMSE: 2150.57\n  > Boosting Round 8, Residual RMSE: 2046.51\n  > Boosting Round 9, Residual RMSE: 1950.21\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1897.18\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3385.62\n  > Boosting Round 1, Residual RMSE: 3126.81\n  > Boosting Round 2, Residual RMSE: 2899.49\n  > Boosting Round 3, Residual RMSE: 2696.58\n  > Boosting Round 4, Residual RMSE: 2519.61\n  > Boosting Round 5, Residual RMSE: 2363.03\n  > Boosting Round 6, Residual RMSE: 2227.51\n  > Boosting Round 7, Residual RMSE: 2108.59\n  > Boosting Round 8, Residual RMSE: 2004.08\n  > Boosting Round 9, Residual RMSE: 1913.25\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2252.33\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3508.64\n  > Boosting Round 1, Residual RMSE: 3241.30\n  > Boosting Round 2, Residual RMSE: 3005.54\n  > Boosting Round 3, Residual RMSE: 2797.18\n  > Boosting Round 4, Residual RMSE: 2613.85\n  > Boosting Round 5, Residual RMSE: 2453.04\n  > Boosting Round 6, Residual RMSE: 2313.37\n  > Boosting Round 7, Residual RMSE: 2191.19\n  > Boosting Round 8, Residual RMSE: 2083.52\n  > Boosting Round 9, Residual RMSE: 1990.92\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1947.47\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3509.95\n  > Boosting Round 1, Residual RMSE: 3242.22\n  > Boosting Round 2, Residual RMSE: 3004.58\n  > Boosting Round 3, Residual RMSE: 2795.43\n  > Boosting Round 4, Residual RMSE: 2610.72\n  > Boosting Round 5, Residual RMSE: 2448.70\n  > Boosting Round 6, Residual RMSE: 2308.29\n  > Boosting Round 7, Residual RMSE: 2185.17\n  > Boosting Round 8, Residual RMSE: 2077.61\n  > Boosting Round 9, Residual RMSE: 1983.01\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1893.90\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3487.87\n  > Boosting Round 1, Residual RMSE: 3221.17\n  > Boosting Round 2, Residual RMSE: 2985.08\n  > Boosting Round 3, Residual RMSE: 2777.23\n  > Boosting Round 4, Residual RMSE: 2593.52\n  > Boosting Round 5, Residual RMSE: 2432.92\n  > Boosting Round 6, Residual RMSE: 2292.55\n  > Boosting Round 7, Residual RMSE: 2170.29\n  > Boosting Round 8, Residual RMSE: 2064.32\n  > Boosting Round 9, Residual RMSE: 1969.68\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2221.89\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 3, 'lr': 0.1, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2042.55\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 4, 'lr': 0.05, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3586.91\n  > Boosting Round 1, Residual RMSE: 3437.58\n  > Boosting Round 2, Residual RMSE: 3297.18\n  > Boosting Round 3, Residual RMSE: 3163.95\n  > Boosting Round 4, Residual RMSE: 3038.96\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2935.96\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3522.95\n  > Boosting Round 1, Residual RMSE: 3376.61\n  > Boosting Round 2, Residual RMSE: 3238.82\n  > Boosting Round 3, Residual RMSE: 3108.50\n  > Boosting Round 4, Residual RMSE: 2985.88\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3353.55\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3651.47\n  > Boosting Round 1, Residual RMSE: 3500.42\n  > Boosting Round 2, Residual RMSE: 3357.53\n  > Boosting Round 3, Residual RMSE: 3223.27\n  > Boosting Round 4, Residual RMSE: 3096.26\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3090.33\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3653.84\n  > Boosting Round 1, Residual RMSE: 3502.13\n  > Boosting Round 2, Residual RMSE: 3359.06\n  > Boosting Round 3, Residual RMSE: 3224.01\n  > Boosting Round 4, Residual RMSE: 3096.04\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2985.99\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3631.05\n  > Boosting Round 1, Residual RMSE: 3480.06\n  > Boosting Round 2, Residual RMSE: 3337.68\n  > Boosting Round 3, Residual RMSE: 3203.45\n  > Boosting Round 4, Residual RMSE: 3076.90\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3371.86\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 4, 'lr': 0.05, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 3147.54\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 4, 'lr': 0.05, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3586.91\n  > Boosting Round 1, Residual RMSE: 3437.58\n  > Boosting Round 2, Residual RMSE: 3297.18\n  > Boosting Round 3, Residual RMSE: 3163.95\n  > Boosting Round 4, Residual RMSE: 3038.96\n  > Boosting Round 5, Residual RMSE: 2920.57\n  > Boosting Round 6, Residual RMSE: 2808.24\n  > Boosting Round 7, Residual RMSE: 2702.61\n  > Boosting Round 8, Residual RMSE: 2604.37\n  > Boosting Round 9, Residual RMSE: 2510.35\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2427.32\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3522.95\n  > Boosting Round 1, Residual RMSE: 3376.61\n  > Boosting Round 2, Residual RMSE: 3238.82\n  > Boosting Round 3, Residual RMSE: 3108.50\n  > Boosting Round 4, Residual RMSE: 2985.88\n  > Boosting Round 5, Residual RMSE: 2870.39\n  > Boosting Round 6, Residual RMSE: 2760.39\n  > Boosting Round 7, Residual RMSE: 2657.10\n  > Boosting Round 8, Residual RMSE: 2559.30\n  > Boosting Round 9, Residual RMSE: 2466.93\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2817.48\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3651.47\n  > Boosting Round 1, Residual RMSE: 3500.42\n  > Boosting Round 2, Residual RMSE: 3357.53\n  > Boosting Round 3, Residual RMSE: 3223.27\n  > Boosting Round 4, Residual RMSE: 3096.26\n  > Boosting Round 5, Residual RMSE: 2977.00\n  > Boosting Round 6, Residual RMSE: 2864.30\n  > Boosting Round 7, Residual RMSE: 2756.28\n  > Boosting Round 8, Residual RMSE: 2655.73\n  > Boosting Round 9, Residual RMSE: 2561.41\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2541.23\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3653.84\n  > Boosting Round 1, Residual RMSE: 3502.13\n  > Boosting Round 2, Residual RMSE: 3359.06\n  > Boosting Round 3, Residual RMSE: 3224.01\n  > Boosting Round 4, Residual RMSE: 3096.04\n  > Boosting Round 5, Residual RMSE: 2976.24\n  > Boosting Round 6, Residual RMSE: 2862.32\n  > Boosting Round 7, Residual RMSE: 2755.52\n  > Boosting Round 8, Residual RMSE: 2655.23\n  > Boosting Round 9, Residual RMSE: 2559.71\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2456.69\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3631.05\n  > Boosting Round 1, Residual RMSE: 3480.06\n  > Boosting Round 2, Residual RMSE: 3337.68\n  > Boosting Round 3, Residual RMSE: 3203.45\n  > Boosting Round 4, Residual RMSE: 3076.90\n  > Boosting Round 5, Residual RMSE: 2956.92\n  > Boosting Round 6, Residual RMSE: 2844.33\n  > Boosting Round 7, Residual RMSE: 2737.60\n  > Boosting Round 8, Residual RMSE: 2637.72\n  > Boosting Round 9, Residual RMSE: 2542.54\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2823.13\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 4, 'lr': 0.05, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2613.17\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 4, 'lr': 0.1, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3430.39\n  > Boosting Round 1, Residual RMSE: 3150.19\n  > Boosting Round 2, Residual RMSE: 2903.22\n  > Boosting Round 3, Residual RMSE: 2682.11\n  > Boosting Round 4, Residual RMSE: 2487.58\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2409.28\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3369.23\n  > Boosting Round 1, Residual RMSE: 3095.20\n  > Boosting Round 2, Residual RMSE: 2852.30\n  > Boosting Round 3, Residual RMSE: 2635.71\n  > Boosting Round 4, Residual RMSE: 2444.03\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2791.58\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3492.73\n  > Boosting Round 1, Residual RMSE: 3209.20\n  > Boosting Round 2, Residual RMSE: 2958.20\n  > Boosting Round 3, Residual RMSE: 2735.77\n  > Boosting Round 4, Residual RMSE: 2536.02\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2516.72\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3494.33\n  > Boosting Round 1, Residual RMSE: 3209.32\n  > Boosting Round 2, Residual RMSE: 2957.86\n  > Boosting Round 3, Residual RMSE: 2733.42\n  > Boosting Round 4, Residual RMSE: 2536.56\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2434.14\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3472.57\n  > Boosting Round 1, Residual RMSE: 3189.79\n  > Boosting Round 2, Residual RMSE: 2939.06\n  > Boosting Round 3, Residual RMSE: 2715.32\n  > Boosting Round 4, Residual RMSE: 2519.60\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2800.89\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 4, 'lr': 0.1, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 2590.52\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 4, 'lr': 0.1, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3430.39\n  > Boosting Round 1, Residual RMSE: 3150.19\n  > Boosting Round 2, Residual RMSE: 2903.22\n  > Boosting Round 3, Residual RMSE: 2682.11\n  > Boosting Round 4, Residual RMSE: 2487.58\n  > Boosting Round 5, Residual RMSE: 2315.01\n  > Boosting Round 6, Residual RMSE: 2162.72\n  > Boosting Round 7, Residual RMSE: 2029.95\n  > Boosting Round 8, Residual RMSE: 1913.02\n  > Boosting Round 9, Residual RMSE: 1810.32\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1752.17\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3369.23\n  > Boosting Round 1, Residual RMSE: 3095.20\n  > Boosting Round 2, Residual RMSE: 2852.30\n  > Boosting Round 3, Residual RMSE: 2635.71\n  > Boosting Round 4, Residual RMSE: 2444.03\n  > Boosting Round 5, Residual RMSE: 2274.59\n  > Boosting Round 6, Residual RMSE: 2123.65\n  > Boosting Round 7, Residual RMSE: 1991.51\n  > Boosting Round 8, Residual RMSE: 1875.40\n  > Boosting Round 9, Residual RMSE: 1773.91\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2111.34\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3492.73\n  > Boosting Round 1, Residual RMSE: 3209.20\n  > Boosting Round 2, Residual RMSE: 2958.20\n  > Boosting Round 3, Residual RMSE: 2735.77\n  > Boosting Round 4, Residual RMSE: 2536.02\n  > Boosting Round 5, Residual RMSE: 2363.24\n  > Boosting Round 6, Residual RMSE: 2208.95\n  > Boosting Round 7, Residual RMSE: 2072.45\n  > Boosting Round 8, Residual RMSE: 1953.98\n  > Boosting Round 9, Residual RMSE: 1850.26\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1804.17\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3494.33\n  > Boosting Round 1, Residual RMSE: 3209.32\n  > Boosting Round 2, Residual RMSE: 2957.86\n  > Boosting Round 3, Residual RMSE: 2733.42\n  > Boosting Round 4, Residual RMSE: 2536.56\n  > Boosting Round 5, Residual RMSE: 2360.84\n  > Boosting Round 6, Residual RMSE: 2204.00\n  > Boosting Round 7, Residual RMSE: 2067.16\n  > Boosting Round 8, Residual RMSE: 1945.86\n  > Boosting Round 9, Residual RMSE: 1841.21\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1742.90\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3472.57\n  > Boosting Round 1, Residual RMSE: 3189.79\n  > Boosting Round 2, Residual RMSE: 2939.06\n  > Boosting Round 3, Residual RMSE: 2715.32\n  > Boosting Round 4, Residual RMSE: 2519.60\n  > Boosting Round 5, Residual RMSE: 2344.14\n  > Boosting Round 6, Residual RMSE: 2187.52\n  > Boosting Round 7, Residual RMSE: 2050.96\n  > Boosting Round 8, Residual RMSE: 1934.04\n  > Boosting Round 9, Residual RMSE: 1828.23\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2080.50\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 4, 'lr': 0.1, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 1898.22\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 5, 'lr': 0.05, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3581.48\n  > Boosting Round 1, Residual RMSE: 3426.76\n  > Boosting Round 2, Residual RMSE: 3280.65\n  > Boosting Round 3, Residual RMSE: 3142.65\n  > Boosting Round 4, Residual RMSE: 3011.77\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2905.51\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3517.47\n  > Boosting Round 1, Residual RMSE: 3365.27\n  > Boosting Round 2, Residual RMSE: 3221.70\n  > Boosting Round 3, Residual RMSE: 3086.03\n  > Boosting Round 4, Residual RMSE: 2958.15\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3321.47\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3645.70\n  > Boosting Round 1, Residual RMSE: 3489.15\n  > Boosting Round 2, Residual RMSE: 3340.84\n  > Boosting Round 3, Residual RMSE: 3201.62\n  > Boosting Round 4, Residual RMSE: 3070.05\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3064.74\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3648.20\n  > Boosting Round 1, Residual RMSE: 3491.10\n  > Boosting Round 2, Residual RMSE: 3342.67\n  > Boosting Round 3, Residual RMSE: 3201.89\n  > Boosting Round 4, Residual RMSE: 3069.35\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2958.95\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3625.17\n  > Boosting Round 1, Residual RMSE: 3468.32\n  > Boosting Round 2, Residual RMSE: 3320.59\n  > Boosting Round 3, Residual RMSE: 3181.15\n  > Boosting Round 4, Residual RMSE: 3049.01\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3341.99\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 5, 'lr': 0.05, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 3118.53\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 5, 'lr': 0.05, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3581.48\n  > Boosting Round 1, Residual RMSE: 3426.76\n  > Boosting Round 2, Residual RMSE: 3280.65\n  > Boosting Round 3, Residual RMSE: 3142.65\n  > Boosting Round 4, Residual RMSE: 3011.77\n  > Boosting Round 5, Residual RMSE: 2888.18\n  > Boosting Round 6, Residual RMSE: 2770.87\n  > Boosting Round 7, Residual RMSE: 2661.39\n  > Boosting Round 8, Residual RMSE: 2556.59\n  > Boosting Round 9, Residual RMSE: 2457.04\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2369.06\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3517.47\n  > Boosting Round 1, Residual RMSE: 3365.27\n  > Boosting Round 2, Residual RMSE: 3221.70\n  > Boosting Round 3, Residual RMSE: 3086.03\n  > Boosting Round 4, Residual RMSE: 2958.15\n  > Boosting Round 5, Residual RMSE: 2837.18\n  > Boosting Round 6, Residual RMSE: 2722.84\n  > Boosting Round 7, Residual RMSE: 2614.88\n  > Boosting Round 8, Residual RMSE: 2511.51\n  > Boosting Round 9, Residual RMSE: 2413.65\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2759.10\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3645.70\n  > Boosting Round 1, Residual RMSE: 3489.15\n  > Boosting Round 2, Residual RMSE: 3340.84\n  > Boosting Round 3, Residual RMSE: 3201.62\n  > Boosting Round 4, Residual RMSE: 3070.05\n  > Boosting Round 5, Residual RMSE: 2944.68\n  > Boosting Round 6, Residual RMSE: 2826.43\n  > Boosting Round 7, Residual RMSE: 2715.41\n  > Boosting Round 8, Residual RMSE: 2608.67\n  > Boosting Round 9, Residual RMSE: 2508.95\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2490.20\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3648.20\n  > Boosting Round 1, Residual RMSE: 3491.10\n  > Boosting Round 2, Residual RMSE: 3342.67\n  > Boosting Round 3, Residual RMSE: 3201.89\n  > Boosting Round 4, Residual RMSE: 3069.35\n  > Boosting Round 5, Residual RMSE: 2943.97\n  > Boosting Round 6, Residual RMSE: 2825.23\n  > Boosting Round 7, Residual RMSE: 2714.12\n  > Boosting Round 8, Residual RMSE: 2608.71\n  > Boosting Round 9, Residual RMSE: 2508.50\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2406.69\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3625.17\n  > Boosting Round 1, Residual RMSE: 3468.32\n  > Boosting Round 2, Residual RMSE: 3320.59\n  > Boosting Round 3, Residual RMSE: 3181.15\n  > Boosting Round 4, Residual RMSE: 3049.01\n  > Boosting Round 5, Residual RMSE: 2924.69\n  > Boosting Round 6, Residual RMSE: 2807.05\n  > Boosting Round 7, Residual RMSE: 2695.32\n  > Boosting Round 8, Residual RMSE: 2591.00\n  > Boosting Round 9, Residual RMSE: 2491.86\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2771.68\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 5, 'lr': 0.05, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2559.35\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 5, 'lr': 0.1, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3419.32\n  > Boosting Round 1, Residual RMSE: 3127.85\n  > Boosting Round 2, Residual RMSE: 2871.01\n  > Boosting Round 3, Residual RMSE: 2638.84\n  > Boosting Round 4, Residual RMSE: 2434.28\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2347.66\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3358.06\n  > Boosting Round 1, Residual RMSE: 3072.51\n  > Boosting Round 2, Residual RMSE: 2818.33\n  > Boosting Round 3, Residual RMSE: 2592.74\n  > Boosting Round 4, Residual RMSE: 2389.70\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2732.59\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3480.96\n  > Boosting Round 1, Residual RMSE: 3186.57\n  > Boosting Round 2, Residual RMSE: 2923.81\n  > Boosting Round 3, Residual RMSE: 2693.38\n  > Boosting Round 4, Residual RMSE: 2482.87\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2464.12\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3482.83\n  > Boosting Round 1, Residual RMSE: 3188.43\n  > Boosting Round 2, Residual RMSE: 2926.15\n  > Boosting Round 3, Residual RMSE: 2691.24\n  > Boosting Round 4, Residual RMSE: 2483.76\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2381.43\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3460.58\n  > Boosting Round 1, Residual RMSE: 3166.19\n  > Boosting Round 2, Residual RMSE: 2905.08\n  > Boosting Round 3, Residual RMSE: 2673.22\n  > Boosting Round 4, Residual RMSE: 2465.88\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2741.40\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 5, 'lr': 0.1, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 2533.44\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 5, 'lr': 0.1, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3419.32\n  > Boosting Round 1, Residual RMSE: 3127.85\n  > Boosting Round 2, Residual RMSE: 2871.01\n  > Boosting Round 3, Residual RMSE: 2638.84\n  > Boosting Round 4, Residual RMSE: 2434.28\n  > Boosting Round 5, Residual RMSE: 2250.37\n  > Boosting Round 6, Residual RMSE: 2088.85\n  > Boosting Round 7, Residual RMSE: 1945.05\n  > Boosting Round 8, Residual RMSE: 1816.61\n  > Boosting Round 9, Residual RMSE: 1704.82\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1650.23\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3358.06\n  > Boosting Round 1, Residual RMSE: 3072.51\n  > Boosting Round 2, Residual RMSE: 2818.33\n  > Boosting Round 3, Residual RMSE: 2592.74\n  > Boosting Round 4, Residual RMSE: 2389.70\n  > Boosting Round 5, Residual RMSE: 2209.33\n  > Boosting Round 6, Residual RMSE: 2049.95\n  > Boosting Round 7, Residual RMSE: 1907.03\n  > Boosting Round 8, Residual RMSE: 1782.32\n  > Boosting Round 9, Residual RMSE: 1671.21\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1999.59\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3480.96\n  > Boosting Round 1, Residual RMSE: 3186.57\n  > Boosting Round 2, Residual RMSE: 2923.81\n  > Boosting Round 3, Residual RMSE: 2693.38\n  > Boosting Round 4, Residual RMSE: 2482.87\n  > Boosting Round 5, Residual RMSE: 2299.23\n  > Boosting Round 6, Residual RMSE: 2134.69\n  > Boosting Round 7, Residual RMSE: 1988.82\n  > Boosting Round 8, Residual RMSE: 1862.74\n  > Boosting Round 9, Residual RMSE: 1747.50\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1708.76\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3482.83\n  > Boosting Round 1, Residual RMSE: 3188.43\n  > Boosting Round 2, Residual RMSE: 2926.15\n  > Boosting Round 3, Residual RMSE: 2691.24\n  > Boosting Round 4, Residual RMSE: 2483.76\n  > Boosting Round 5, Residual RMSE: 2297.35\n  > Boosting Round 6, Residual RMSE: 2130.47\n  > Boosting Round 7, Residual RMSE: 1985.86\n  > Boosting Round 8, Residual RMSE: 1857.83\n  > Boosting Round 9, Residual RMSE: 1741.08\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1642.34\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3460.58\n  > Boosting Round 1, Residual RMSE: 3166.19\n  > Boosting Round 2, Residual RMSE: 2905.08\n  > Boosting Round 3, Residual RMSE: 2673.22\n  > Boosting Round 4, Residual RMSE: 2465.88\n  > Boosting Round 5, Residual RMSE: 2283.32\n  > Boosting Round 6, Residual RMSE: 2120.51\n  > Boosting Round 7, Residual RMSE: 1972.73\n  > Boosting Round 8, Residual RMSE: 1842.52\n  > Boosting Round 9, Residual RMSE: 1729.31\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1977.35\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 5, 'lr': 0.1, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 1795.65\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 10, 'lr': 0.05, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3566.06\n  > Boosting Round 1, Residual RMSE: 3396.58\n  > Boosting Round 2, Residual RMSE: 3235.69\n  > Boosting Round 3, Residual RMSE: 3082.70\n  > Boosting Round 4, Residual RMSE: 2938.24\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2836.00\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3503.00\n  > Boosting Round 1, Residual RMSE: 3337.07\n  > Boosting Round 2, Residual RMSE: 3179.70\n  > Boosting Round 3, Residual RMSE: 3030.58\n  > Boosting Round 4, Residual RMSE: 2889.11\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3247.39\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3630.56\n  > Boosting Round 1, Residual RMSE: 3458.99\n  > Boosting Round 2, Residual RMSE: 3296.35\n  > Boosting Round 3, Residual RMSE: 3142.00\n  > Boosting Round 4, Residual RMSE: 2995.86\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2997.30\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3633.44\n  > Boosting Round 1, Residual RMSE: 3461.54\n  > Boosting Round 2, Residual RMSE: 3298.45\n  > Boosting Round 3, Residual RMSE: 3144.03\n  > Boosting Round 4, Residual RMSE: 2997.49\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2903.40\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3610.72\n  > Boosting Round 1, Residual RMSE: 3439.93\n  > Boosting Round 2, Residual RMSE: 3278.00\n  > Boosting Round 3, Residual RMSE: 3124.51\n  > Boosting Round 4, Residual RMSE: 2978.97\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 3256.99\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 10, 'lr': 0.05, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 3048.21\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 10, 'lr': 0.05, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3566.06\n  > Boosting Round 1, Residual RMSE: 3396.58\n  > Boosting Round 2, Residual RMSE: 3235.69\n  > Boosting Round 3, Residual RMSE: 3082.70\n  > Boosting Round 4, Residual RMSE: 2938.24\n  > Boosting Round 5, Residual RMSE: 2800.47\n  > Boosting Round 6, Residual RMSE: 2669.44\n  > Boosting Round 7, Residual RMSE: 2545.48\n  > Boosting Round 8, Residual RMSE: 2427.84\n  > Boosting Round 9, Residual RMSE: 2315.81\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2241.13\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3503.00\n  > Boosting Round 1, Residual RMSE: 3337.07\n  > Boosting Round 2, Residual RMSE: 3179.70\n  > Boosting Round 3, Residual RMSE: 3030.58\n  > Boosting Round 4, Residual RMSE: 2889.11\n  > Boosting Round 5, Residual RMSE: 2754.34\n  > Boosting Round 6, Residual RMSE: 2626.69\n  > Boosting Round 7, Residual RMSE: 2506.05\n  > Boosting Round 8, Residual RMSE: 2391.37\n  > Boosting Round 9, Residual RMSE: 2282.94\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2622.80\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3630.56\n  > Boosting Round 1, Residual RMSE: 3458.99\n  > Boosting Round 2, Residual RMSE: 3296.35\n  > Boosting Round 3, Residual RMSE: 3142.00\n  > Boosting Round 4, Residual RMSE: 2995.86\n  > Boosting Round 5, Residual RMSE: 2857.17\n  > Boosting Round 6, Residual RMSE: 2725.59\n  > Boosting Round 7, Residual RMSE: 2600.71\n  > Boosting Round 8, Residual RMSE: 2482.32\n  > Boosting Round 9, Residual RMSE: 2370.12\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2363.35\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3633.44\n  > Boosting Round 1, Residual RMSE: 3461.54\n  > Boosting Round 2, Residual RMSE: 3298.45\n  > Boosting Round 3, Residual RMSE: 3144.03\n  > Boosting Round 4, Residual RMSE: 2997.49\n  > Boosting Round 5, Residual RMSE: 2858.71\n  > Boosting Round 6, Residual RMSE: 2726.44\n  > Boosting Round 7, Residual RMSE: 2601.29\n  > Boosting Round 8, Residual RMSE: 2482.82\n  > Boosting Round 9, Residual RMSE: 2370.37\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2294.87\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3610.72\n  > Boosting Round 1, Residual RMSE: 3439.93\n  > Boosting Round 2, Residual RMSE: 3278.00\n  > Boosting Round 3, Residual RMSE: 3124.51\n  > Boosting Round 4, Residual RMSE: 2978.97\n  > Boosting Round 5, Residual RMSE: 2840.66\n  > Boosting Round 6, Residual RMSE: 2709.65\n  > Boosting Round 7, Residual RMSE: 2585.41\n  > Boosting Round 8, Residual RMSE: 2467.79\n  > Boosting Round 9, Residual RMSE: 2355.98\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2607.80\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 10, 'lr': 0.05, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2425.99\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3387.77\n  > Boosting Round 1, Residual RMSE: 3067.47\n  > Boosting Round 2, Residual RMSE: 2779.78\n  > Boosting Round 3, Residual RMSE: 2520.25\n  > Boosting Round 4, Residual RMSE: 2287.54\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2213.70\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3328.46\n  > Boosting Round 1, Residual RMSE: 3015.03\n  > Boosting Round 2, Residual RMSE: 2734.01\n  > Boosting Round 3, Residual RMSE: 2481.03\n  > Boosting Round 4, Residual RMSE: 2254.86\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2593.69\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3450.01\n  > Boosting Round 1, Residual RMSE: 3126.30\n  > Boosting Round 2, Residual RMSE: 2835.99\n  > Boosting Round 3, Residual RMSE: 2575.07\n  > Boosting Round 4, Residual RMSE: 2341.62\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2333.82\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3452.62\n  > Boosting Round 1, Residual RMSE: 3127.88\n  > Boosting Round 2, Residual RMSE: 2837.22\n  > Boosting Round 3, Residual RMSE: 2575.47\n  > Boosting Round 4, Residual RMSE: 2341.75\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2267.29\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3431.02\n  > Boosting Round 1, Residual RMSE: 3108.64\n  > Boosting Round 2, Residual RMSE: 2819.61\n  > Boosting Round 3, Residual RMSE: 2560.35\n  > Boosting Round 4, Residual RMSE: 2327.69\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 2576.32\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 2396.96\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3387.77\n  > Boosting Round 1, Residual RMSE: 3067.47\n  > Boosting Round 2, Residual RMSE: 2779.78\n  > Boosting Round 3, Residual RMSE: 2520.25\n  > Boosting Round 4, Residual RMSE: 2287.54\n  > Boosting Round 5, Residual RMSE: 2079.29\n  > Boosting Round 6, Residual RMSE: 1889.98\n  > Boosting Round 7, Residual RMSE: 1720.86\n  > Boosting Round 8, Residual RMSE: 1569.84\n  > Boosting Round 9, Residual RMSE: 1433.98\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1407.57\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3328.46\n  > Boosting Round 1, Residual RMSE: 3015.03\n  > Boosting Round 2, Residual RMSE: 2734.01\n  > Boosting Round 3, Residual RMSE: 2481.03\n  > Boosting Round 4, Residual RMSE: 2254.86\n  > Boosting Round 5, Residual RMSE: 2052.72\n  > Boosting Round 6, Residual RMSE: 1871.54\n  > Boosting Round 7, Residual RMSE: 1709.94\n  > Boosting Round 8, Residual RMSE: 1565.04\n  > Boosting Round 9, Residual RMSE: 1433.56\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1761.67\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3450.01\n  > Boosting Round 1, Residual RMSE: 3126.30\n  > Boosting Round 2, Residual RMSE: 2835.99\n  > Boosting Round 3, Residual RMSE: 2575.07\n  > Boosting Round 4, Residual RMSE: 2341.62\n  > Boosting Round 5, Residual RMSE: 2132.08\n  > Boosting Round 6, Residual RMSE: 1945.02\n  > Boosting Round 7, Residual RMSE: 1776.16\n  > Boosting Round 8, Residual RMSE: 1625.71\n  > Boosting Round 9, Residual RMSE: 1491.56\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1477.97\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3452.62\n  > Boosting Round 1, Residual RMSE: 3127.88\n  > Boosting Round 2, Residual RMSE: 2837.22\n  > Boosting Round 3, Residual RMSE: 2575.47\n  > Boosting Round 4, Residual RMSE: 2341.75\n  > Boosting Round 5, Residual RMSE: 2131.92\n  > Boosting Round 6, Residual RMSE: 1943.64\n  > Boosting Round 7, Residual RMSE: 1775.81\n  > Boosting Round 8, Residual RMSE: 1626.19\n  > Boosting Round 9, Residual RMSE: 1492.29\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1445.89\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3431.02\n  > Boosting Round 1, Residual RMSE: 3108.64\n  > Boosting Round 2, Residual RMSE: 2819.61\n  > Boosting Round 3, Residual RMSE: 2560.35\n  > Boosting Round 4, Residual RMSE: 2327.69\n  > Boosting Round 5, Residual RMSE: 2119.20\n  > Boosting Round 6, Residual RMSE: 1932.54\n  > Boosting Round 7, Residual RMSE: 1765.54\n  > Boosting Round 8, Residual RMSE: 1616.49\n  > Boosting Round 9, Residual RMSE: 1483.35\nFold Results -> LR RMSE: 684.57 | GBDT RMSE: 1696.83\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 1557.99\n========================================\n\n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nGRID SEARCH COMPLETE\nBEST CONFIGURATION For gdb: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 10}\nLOWEST AVERAGE CV RMSE: 1557.99\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#now, we train a model using the best hyperparameters that we found and test it using the test dataset\n# 1. Force all columns to numeric and cast the final array to float32\ntest_df = pd.read_csv(\"test_split.csv\")\nX_train_numeric = df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\nX_test_numeric = test_df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n# 2. Now convert the pure float32 array to a Tensor\nX_train = torch.tensor(X_train_numeric, device=device)\ny_train = torch.tensor(df['Sales'].values.astype(np.float32), device=device)\n\nX_test = torch.tensor(X_test_numeric, device=device)\ny_test = torch.tensor(test_df['Sales'].values.astype(np.float32), device=device)\n\n# Train Custom GBDT (Using best parameters)\ngbdt_model = GBDTScratch(n_estimators=10, max_depth=10, lr=0.1)\ngbdt_model.fit(X_train, y_train)\ngbdt_rmse = get_rmse(y_test, gbdt_model.predict(X_test))\n\nprint(f\"final gbdt rmse = {gbdt_rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:04:44.889650Z","iopub.execute_input":"2026-02-21T12:04:44.890369Z","iopub.status.idle":"2026-02-21T12:14:29.031997Z","shell.execute_reply.started":"2026-02-21T12:04:44.890337Z","shell.execute_reply":"2026-02-21T12:14:29.031284Z"}},"outputs":[{"name":"stdout","text":"  > Boosting Round 0, Residual RMSE: 3480.07\n  > Boosting Round 1, Residual RMSE: 3153.91\n  > Boosting Round 2, Residual RMSE: 2861.62\n  > Boosting Round 3, Residual RMSE: 2599.03\n  > Boosting Round 4, Residual RMSE: 2362.60\n  > Boosting Round 5, Residual RMSE: 2151.61\n  > Boosting Round 6, Residual RMSE: 1962.60\n  > Boosting Round 7, Residual RMSE: 1793.67\n  > Boosting Round 8, Residual RMSE: 1642.41\n  > Boosting Round 9, Residual RMSE: 1506.33\nfinal gbdt rmse = 1549.720458984375\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#now, we increase the number of estimators to 50\n# 1. Force all columns to numeric and cast the final array to float32\ntest_df = pd.read_csv(\"test_split.csv\")\nX_train_numeric = df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\nX_test_numeric = test_df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n# 2. Now convert the pure float32 array to a Tensor\nX_train = torch.tensor(X_train_numeric, device=device)\ny_train = torch.tensor(df['Sales'].values.astype(np.float32), device=device)\n\nX_test = torch.tensor(X_test_numeric, device=device)\ny_test = torch.tensor(test_df['Sales'].values.astype(np.float32), device=device)\n\n# Train Custom GBDT\ngbdt_model = GBDTScratch(n_estimators=50, max_depth=10, lr=0.1)\ngbdt_model.fit(X_train, y_train)\ngbdt_rmse = get_rmse(y_test, gbdt_model.predict(X_test))\n\nprint(f\"final gbdt test rmse = {gbdt_rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:19:33.255311Z","iopub.execute_input":"2026-02-21T12:19:33.255675Z","iopub.status.idle":"2026-02-21T13:07:17.754007Z","shell.execute_reply.started":"2026-02-21T12:19:33.255647Z","shell.execute_reply":"2026-02-21T13:07:17.753234Z"}},"outputs":[{"name":"stdout","text":"  > Boosting Round 0, Residual RMSE: 3480.07\n  > Boosting Round 1, Residual RMSE: 3153.91\n  > Boosting Round 2, Residual RMSE: 2861.62\n  > Boosting Round 3, Residual RMSE: 2599.03\n  > Boosting Round 4, Residual RMSE: 2362.60\n  > Boosting Round 5, Residual RMSE: 2151.61\n  > Boosting Round 6, Residual RMSE: 1962.60\n  > Boosting Round 7, Residual RMSE: 1793.67\n  > Boosting Round 8, Residual RMSE: 1642.41\n  > Boosting Round 9, Residual RMSE: 1506.33\n  > Boosting Round 10, Residual RMSE: 1384.88\n  > Boosting Round 11, Residual RMSE: 1277.50\n  > Boosting Round 12, Residual RMSE: 1180.80\n  > Boosting Round 13, Residual RMSE: 1094.31\n  > Boosting Round 14, Residual RMSE: 1018.64\n  > Boosting Round 15, Residual RMSE: 951.08\n  > Boosting Round 16, Residual RMSE: 891.85\n  > Boosting Round 17, Residual RMSE: 838.30\n  > Boosting Round 18, Residual RMSE: 793.00\n  > Boosting Round 19, Residual RMSE: 752.82\n  > Boosting Round 20, Residual RMSE: 716.70\n  > Boosting Round 21, Residual RMSE: 685.72\n  > Boosting Round 22, Residual RMSE: 658.42\n  > Boosting Round 23, Residual RMSE: 635.38\n  > Boosting Round 24, Residual RMSE: 614.35\n  > Boosting Round 25, Residual RMSE: 596.65\n  > Boosting Round 26, Residual RMSE: 581.15\n  > Boosting Round 27, Residual RMSE: 567.63\n  > Boosting Round 28, Residual RMSE: 555.20\n  > Boosting Round 29, Residual RMSE: 544.89\n  > Boosting Round 30, Residual RMSE: 535.27\n  > Boosting Round 31, Residual RMSE: 526.57\n  > Boosting Round 32, Residual RMSE: 518.53\n  > Boosting Round 33, Residual RMSE: 512.00\n  > Boosting Round 34, Residual RMSE: 505.76\n  > Boosting Round 35, Residual RMSE: 499.48\n  > Boosting Round 36, Residual RMSE: 494.40\n  > Boosting Round 37, Residual RMSE: 489.83\n  > Boosting Round 38, Residual RMSE: 485.46\n  > Boosting Round 39, Residual RMSE: 482.10\n  > Boosting Round 40, Residual RMSE: 478.60\n  > Boosting Round 41, Residual RMSE: 475.39\n  > Boosting Round 42, Residual RMSE: 472.05\n  > Boosting Round 43, Residual RMSE: 469.52\n  > Boosting Round 44, Residual RMSE: 466.86\n  > Boosting Round 45, Residual RMSE: 464.45\n  > Boosting Round 46, Residual RMSE: 462.27\n  > Boosting Round 47, Residual RMSE: 459.68\n  > Boosting Round 48, Residual RMSE: 457.83\n  > Boosting Round 49, Residual RMSE: 455.78\nfinal gbdt test rmse = 508.426025390625\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#training and testing the base line\n# 1. Force all columns to numeric and cast the final array to float32\ntest_df = pd.read_csv(\"test_split.csv\")\nX_train_numeric = df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\nX_test_numeric = test_df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n# 2. Now convert the pure float32 array to a Tensor\nX_train = torch.tensor(X_train_numeric, device=device)\ny_train = torch.tensor(df['Sales'].values.astype(np.float32), device=device)\n\nX_test = torch.tensor(X_test_numeric, device=device)\ny_test = torch.tensor(test_df['Sales'].values.astype(np.float32), device=device)\n# Train Scratch Linear Regression\nlr_model = LinearRegressionScratch()\nlr_model.fit(X_train, y_train)\nlr_rmse = get_rmse(y_test, lr_model.predict(X_test))\nprint(f\"final base line (regression) test rmse = {lr_rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T13:26:19.896429Z","iopub.execute_input":"2026-02-21T13:26:19.896750Z","iopub.status.idle":"2026-02-21T13:26:33.074513Z","shell.execute_reply.started":"2026-02-21T13:26:19.896726Z","shell.execute_reply":"2026-02-21T13:26:33.073570Z"}},"outputs":[{"name":"stdout","text":"final base line (regression) test rmse = 1330.7149658203125\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"torch.save(gbdt_model, \"gbdt_model.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T13:31:33.669032Z","iopub.execute_input":"2026-02-21T13:31:33.669353Z","iopub.status.idle":"2026-02-21T13:31:40.628710Z","shell.execute_reply.started":"2026-02-21T13:31:33.669330Z","shell.execute_reply":"2026-02-21T13:31:40.627820Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}