{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport gdown\nimport os\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\n# --- CONFIGURATION ---\nwarnings.filterwarnings('ignore')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 1. DOWNLOAD DATA\nfile_ids = {\n    'train_split.csv': '1IsyR3Xb_2cfvo457Fh8nE72VTifZb64W',\n    'val_split.csv': '1wX4PeKO6fPeLmICA2xmJ3gDUqv_MjE4B',\n    'test_split.csv': '1YSyXByVC105ifTZf-FX9IFjlAbZXbdSj',\n    'feature_columns.txt': '1PJqBlBZuxocIyHWywBhtaynUn2Pw-y5_'\n}\ndef download_from_drive(ids):\n    for filename, fid in ids.items():\n        if not os.path.exists(filename):\n            url = f'https://drive.google.com/uc?id={fid}'\n            gdown.download(url, filename, quiet=False)\n\ndownload_from_drive(file_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T14:44:23.075652Z","iopub.execute_input":"2026-02-21T14:44:23.075934Z","iopub.status.idle":"2026-02-21T14:44:47.245455Z","shell.execute_reply.started":"2026-02-21T14:44:23.075905Z","shell.execute_reply":"2026-02-21T14:44:47.244791Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1IsyR3Xb_2cfvo457Fh8nE72VTifZb64W\nFrom (redirected): https://drive.google.com/uc?id=1IsyR3Xb_2cfvo457Fh8nE72VTifZb64W&confirm=t&uuid=7bd5ed5b-47c5-45ca-a08b-37973ae7b12f\nTo: /kaggle/working/train_split.csv\n100%|██████████| 1.23G/1.23G [00:10<00:00, 113MB/s] \nDownloading...\nFrom (original): https://drive.google.com/uc?id=1wX4PeKO6fPeLmICA2xmJ3gDUqv_MjE4B\nFrom (redirected): https://drive.google.com/uc?id=1wX4PeKO6fPeLmICA2xmJ3gDUqv_MjE4B&confirm=t&uuid=118aafdf-b407-4d89-b1c6-d1eb7ecc8993\nTo: /kaggle/working/val_split.csv\n100%|██████████| 161M/161M [00:01<00:00, 144MB/s]  \nDownloading...\nFrom (original): https://drive.google.com/uc?id=1YSyXByVC105ifTZf-FX9IFjlAbZXbdSj\nFrom (redirected): https://drive.google.com/uc?id=1YSyXByVC105ifTZf-FX9IFjlAbZXbdSj&confirm=t&uuid=84506f4a-decd-4bb5-acc7-b843d9f33dd0\nTo: /kaggle/working/test_split.csv\n100%|██████████| 161M/161M [00:01<00:00, 143MB/s]  \nDownloading...\nFrom: https://drive.google.com/uc?id=1PJqBlBZuxocIyHWywBhtaynUn2Pw-y5_\nTo: /kaggle/working/feature_columns.txt\n100%|██████████| 3.27k/3.27k [00:00<00:00, 9.56MB/s]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 2. DATA LOADING & PREPARATION\n# Load full data and sort by date to ensure temporal integrity\ndf_train = pd.read_csv('train_split.csv')\ndf_val = pd.read_csv('val_split.csv')\ndf = pd.concat([df_train, df_val], ignore_index=True)\n\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values('Date') \n\nwith open('feature_columns.txt', 'r') as f:\n    features = [line.strip() for line in f.readlines()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T14:44:47.246570Z","iopub.execute_input":"2026-02-21T14:44:47.247034Z","iopub.status.idle":"2026-02-21T14:45:08.574576Z","shell.execute_reply.started":"2026-02-21T14:44:47.247008Z","shell.execute_reply":"2026-02-21T14:45:08.573926Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# 3. SCRATCH LINEAR REGRESSION (CUDA)\nclass LinearRegressionScratch:\n    def fit(self, X, y):\n        # Adding bias term\n        ones = torch.ones((X.shape[0], 1), device=device)\n        X_b = torch.cat((ones, X), dim=1)\n        # Normal Equation using Pseudo-inverse for numerical stability\n        self.weights = torch.linalg.pinv(X_b.T @ X_b) @ X_b.T @ y\n        \n    def predict(self, X):\n        ones = torch.ones((X.shape[0], 1), device=device)\n        X_b = torch.cat((ones, X), dim=1)\n        # Clamp at 0 because sales cannot be negative\n        return torch.clamp(X_b @ self.weights, min=0)\n\n# 4. SCRATCH GRADIENT BOOSTED REGRESSOR (CUDA)\nclass GBDTScratch:\n    def __init__(self, n_estimators=10, max_depth=3, lr=0.1):\n        self.n_estimators = n_estimators\n        self.max_depth = max_depth\n        self.lr = lr\n        self.trees = []\n\n    def fit(self, X, y):\n        # Initial prediction (mean of target)\n        self.base_pred = torch.mean(y)\n        current_preds = torch.full_like(y, self.base_pred)\n\n        for i in range(self.n_estimators):\n            # Gradient Boosting: Predict the residuals (errors)\n            residuals = y - current_preds\n            \n            # Build tree on residuals\n            tree = self._build_tree(X, residuals, depth=0)\n            self.trees.append(tree)\n            \n            # Update overall predictions with learning rate\n            current_preds += self.lr * self._predict_tree(X, tree)\n            \n            # Requirement: Report RMSE at each boosting stage\n           \n            rmse = torch.sqrt(torch.mean((y - current_preds)**2))\n            print(f\"  > Boosting Round {i}, Residual RMSE: {rmse.item():.2f}\")\n\n    def _build_tree(self, X, res, depth):\n        if depth >= self.max_depth or len(res) < 10:\n            return torch.mean(res)\n\n        n_features = X.shape[1]\n        best_gain = -1\n        split_idx, split_val = 0, 0\n\n        # Optimization: Median-split on sampled features for speed\n        for f_idx in range(n_features):\n            feat_vals = X[:, f_idx]\n            threshold = torch.median(feat_vals)\n            \n            left_mask = feat_vals <= threshold\n            right_mask = ~left_mask\n            \n            if left_mask.sum() == 0 or right_mask.sum() == 0: continue\n            \n            # Variance Reduction Gain\n            gain = torch.var(res) - (left_mask.sum()*torch.var(res[left_mask]) + \n                                     right_mask.sum()*torch.var(res[right_mask])) / len(res)\n            \n            if gain > best_gain:\n                best_gain, split_idx, split_val = gain, f_idx, threshold\n\n        left_mask = X[:, split_idx] <= split_val\n        return {\n            'split_idx': split_idx,\n            'split_val': split_val,\n            'left': self._build_tree(X[left_mask], res[left_mask], depth+1),\n            'right': self._build_tree(X[~left_mask], res[~left_mask], depth+1)\n        }\n\n    def _predict_tree(self, X, tree):\n        if not isinstance(tree, dict):\n            return torch.full((X.shape[0],), tree, device=device)\n        \n        preds = torch.zeros(X.shape[0], device=device)\n        left_mask = X[:, tree['split_idx']] <= tree['split_val']\n        \n        preds[left_mask] = self._predict_tree(X[left_mask], tree['left'])\n        preds[~left_mask] = self._predict_tree(X[~left_mask], tree['right'])\n        return preds\n\n    def predict(self, X):\n        y_pred = torch.full((X.shape[0],), self.base_pred, device=device)\n        for tree in self.trees:\n            y_pred += self.lr * self._predict_tree(X, tree)\n        return torch.clamp(y_pred, min=0)\n\n# 5. EVALUATION: STORE-AWARE TEMPORAL CROSS-VALIDATION\ndef get_rmse(y_true, y_pred):\n    return torch.sqrt(torch.mean((y_true - y_pred)**2)).item()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-21T14:45:08.575472Z","iopub.execute_input":"2026-02-21T14:45:08.575723Z","iopub.status.idle":"2026-02-21T14:45:08.590331Z","shell.execute_reply.started":"2026-02-21T14:45:08.575695Z","shell.execute_reply":"2026-02-21T14:45:08.589479Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"for column in df[features].columns:\n    if df[column].dtype == 'object':\n        print(f\"Object Column Found: {column}\")\n        # Show a few unique values to see what the data looks like\n        print(f\"Sample values: {train_df[column].unique()[:5]}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T14:45:08.592031Z","iopub.execute_input":"2026-02-21T14:45:08.592375Z","iopub.status.idle":"2026-02-21T14:45:08.899270Z","shell.execute_reply.started":"2026-02-21T14:45:08.592354Z","shell.execute_reply":"2026-02-21T14:45:08.898577Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tscv = TimeSeriesSplit(n_splits=5)\nfold_results_lr = []\nfor fold, (train_idx, val_idx) in enumerate(tscv.split(df)):\n    print(f\"\\n--- FOLD {fold + 1} / 5 ---\")\n    \n    # Split data based on time-indices\n    train_fold = df.iloc[train_idx]\n    val_fold = df.iloc[val_idx]\n    # 1. Force all columns to numeric and cast the final array to float32\n    X_train_numeric = train_fold[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n    X_val_numeric = val_fold[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n    # 2. Now convert the pure float32 array to a Tensor\n    X_train = torch.tensor(X_train_numeric, device=device)\n    y_train = torch.tensor(train_fold['Sales'].values.astype(np.float32), device=device)\n    \n    X_val = torch.tensor(X_val_numeric, device=device)\n    y_val = torch.tensor(val_fold['Sales'].values.astype(np.float32), device=device)\n\n    # Train Scratch Linear Regression\n    lr_model = LinearRegressionScratch()\n    lr_model.fit(X_train, y_train)\n    lr_rmse = get_rmse(y_val, lr_model.predict(X_val))\n    fold_results_lr.append(lr_rmse)\n    \nprint(f\"Average Linear Regression RMSE: {np.mean(fold_results_lr):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T14:45:08.900373Z","iopub.execute_input":"2026-02-21T14:45:08.901175Z","iopub.status.idle":"2026-02-21T14:45:52.103980Z","shell.execute_reply.started":"2026-02-21T14:45:08.901140Z","shell.execute_reply":"2026-02-21T14:45:52.103189Z"}},"outputs":[{"name":"stdout","text":"\n--- FOLD 1 / 5 ---\n\n--- FOLD 2 / 5 ---\n\n--- FOLD 3 / 5 ---\n\n--- FOLD 4 / 5 ---\n\n--- FOLD 5 / 5 ---\nAverage Linear Regression RMSE: 4106.09\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import itertools\n\n# 1. Define the Hyperparameter Grid\nparam_grid = {\n    'max_depth': [3, 4, 5, 10],\n    'lr': [0.05, 0.1],\n    'n_estimators':[5, 10]\n}\n\n# Generate all combinations\nkeys, values = zip(*param_grid.items())\npermutations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n\nbest_overall_rmse = float('inf')\nbest_config = None\n\nprint(f\"Starting Grid Search over {len(permutations)} combinations...\")\n\n# --- NEW OUTER LOOP FOR GRID SEARCH ---\nfor params in permutations:\n    print(f\"\\n\" + \"#\"*60)\n    print(f\"TESTING CONFIGURATION: {params}\")\n    print(\"#\"*60)\n\n    # Defining the Cross-Validation strategy\n    # This ensures we test on multiple future windows of the stores\n    tscv = TimeSeriesSplit(n_splits=5)\n    fold_results_gbdt = []\n\n    print(\"Starting Store-Aware Temporal Cross-Validation...\")\n\n    for fold, (train_idx, val_idx) in enumerate(tscv.split(df)):\n        print(f\"\\n--- FOLD {fold + 1} / 5 ---\")\n        \n        # Split data based on time-indices\n        train_fold = df.iloc[train_idx]\n        val_fold = df.iloc[val_idx]\n        \n        # 1. Force all columns to numeric and cast the final array to float32\n        X_train_numeric = train_fold[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n        X_val_numeric = val_fold[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n        # 2. Now convert the pure float32 array to a Tensor\n        X_train = torch.tensor(X_train_numeric, device=device)\n        y_train = torch.tensor(train_fold['Sales'].values.astype(np.float32), device=device)\n        \n        X_val = torch.tensor(X_val_numeric, device=device)\n        y_val = torch.tensor(val_fold['Sales'].values.astype(np.float32), device=device)\n\n        # Train Custom GBDT (Using parameters from Grid Search)\n        gbdt_model = GBDTScratch(n_estimators=params[\"n_estimators\"], max_depth=params['max_depth'], lr=params['lr'])\n        gbdt_model.fit(X_train, y_train)\n        gbdt_rmse = get_rmse(y_val, gbdt_model.predict(X_val))\n        fold_results_gbdt.append(gbdt_rmse)\n\n        print(f\"Fold Results -> LR RMSE: {lr_rmse:.2f} | GBDT RMSE: {gbdt_rmse:.2f}\")\n\n    # Calculate Average for this config\n    avg_gbdt_rmse = np.mean(fold_results_gbdt)\n    \n    # Track the best configuration\n    if avg_gbdt_rmse < best_overall_rmse:\n        best_overall_rmse = avg_gbdt_rmse\n        best_config = params\n\n    # 6. SUMMARY FOR CURRENT CONFIGURATION\n    print(\"\\n\" + \"=\"*40)\n    print(f\"SUMMARY FOR CONFIG: {params}\")\n    print(\"=\"*40)\n    print(f\"Average Custom GBDT RMSE: {avg_gbdt_rmse:.2f}\")\n    print(\"=\"*40)\n\n# FINAL GLOBAL RESULT\nprint(\"\\n\\n\" + \"!\"*60)\nprint(f\"GRID SEARCH COMPLETE\")\nprint(f\"BEST CONFIGURATION For gdb: {best_config}\")\nprint(f\"LOWEST AVERAGE CV RMSE: {best_overall_rmse:.2f}\")\nprint(\"!\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T14:45:52.105071Z","iopub.execute_input":"2026-02-21T14:45:52.105350Z","iopub.status.idle":"2026-02-21T18:04:28.529970Z","shell.execute_reply.started":"2026-02-21T14:45:52.105310Z","shell.execute_reply":"2026-02-21T18:04:28.528795Z"}},"outputs":[{"name":"stdout","text":"Starting Grid Search over 16 combinations...\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 3, 'lr': 0.05, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3594.27\n  > Boosting Round 1, Residual RMSE: 3452.72\n  > Boosting Round 2, Residual RMSE: 3319.41\n  > Boosting Round 3, Residual RMSE: 3194.00\n  > Boosting Round 4, Residual RMSE: 3075.94\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2969.87\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3530.79\n  > Boosting Round 1, Residual RMSE: 3392.24\n  > Boosting Round 2, Residual RMSE: 3261.62\n  > Boosting Round 3, Residual RMSE: 3138.68\n  > Boosting Round 4, Residual RMSE: 3023.09\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3398.89\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3659.28\n  > Boosting Round 1, Residual RMSE: 3516.12\n  > Boosting Round 2, Residual RMSE: 3381.16\n  > Boosting Round 3, Residual RMSE: 3254.50\n  > Boosting Round 4, Residual RMSE: 3135.06\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3127.16\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3661.51\n  > Boosting Round 1, Residual RMSE: 3517.48\n  > Boosting Round 2, Residual RMSE: 3382.32\n  > Boosting Round 3, Residual RMSE: 3254.33\n  > Boosting Round 4, Residual RMSE: 3133.85\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3019.37\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3638.57\n  > Boosting Round 1, Residual RMSE: 3495.80\n  > Boosting Round 2, Residual RMSE: 3360.63\n  > Boosting Round 3, Residual RMSE: 3233.30\n  > Boosting Round 4, Residual RMSE: 3114.05\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3411.29\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 3, 'lr': 0.05, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 3185.32\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 3, 'lr': 0.05, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3594.27\n  > Boosting Round 1, Residual RMSE: 3452.72\n  > Boosting Round 2, Residual RMSE: 3319.41\n  > Boosting Round 3, Residual RMSE: 3194.00\n  > Boosting Round 4, Residual RMSE: 3075.94\n  > Boosting Round 5, Residual RMSE: 2964.17\n  > Boosting Round 6, Residual RMSE: 2859.49\n  > Boosting Round 7, Residual RMSE: 2761.22\n  > Boosting Round 8, Residual RMSE: 2669.05\n  > Boosting Round 9, Residual RMSE: 2582.64\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2494.02\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3530.79\n  > Boosting Round 1, Residual RMSE: 3392.24\n  > Boosting Round 2, Residual RMSE: 3261.62\n  > Boosting Round 3, Residual RMSE: 3138.68\n  > Boosting Round 4, Residual RMSE: 3023.09\n  > Boosting Round 5, Residual RMSE: 2913.72\n  > Boosting Round 6, Residual RMSE: 2811.01\n  > Boosting Round 7, Residual RMSE: 2714.29\n  > Boosting Round 8, Residual RMSE: 2623.63\n  > Boosting Round 9, Residual RMSE: 2538.16\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2898.17\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3659.28\n  > Boosting Round 1, Residual RMSE: 3516.12\n  > Boosting Round 2, Residual RMSE: 3381.16\n  > Boosting Round 3, Residual RMSE: 3254.50\n  > Boosting Round 4, Residual RMSE: 3135.06\n  > Boosting Round 5, Residual RMSE: 3022.41\n  > Boosting Round 6, Residual RMSE: 2916.54\n  > Boosting Round 7, Residual RMSE: 2816.67\n  > Boosting Round 8, Residual RMSE: 2722.79\n  > Boosting Round 9, Residual RMSE: 2634.76\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2610.27\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3661.51\n  > Boosting Round 1, Residual RMSE: 3517.48\n  > Boosting Round 2, Residual RMSE: 3382.32\n  > Boosting Round 3, Residual RMSE: 3254.33\n  > Boosting Round 4, Residual RMSE: 3133.85\n  > Boosting Round 5, Residual RMSE: 3020.90\n  > Boosting Round 6, Residual RMSE: 2913.75\n  > Boosting Round 7, Residual RMSE: 2813.90\n  > Boosting Round 8, Residual RMSE: 2719.26\n  > Boosting Round 9, Residual RMSE: 2630.45\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2523.92\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3638.57\n  > Boosting Round 1, Residual RMSE: 3495.80\n  > Boosting Round 2, Residual RMSE: 3360.63\n  > Boosting Round 3, Residual RMSE: 3233.30\n  > Boosting Round 4, Residual RMSE: 3114.05\n  > Boosting Round 5, Residual RMSE: 3000.96\n  > Boosting Round 6, Residual RMSE: 2894.59\n  > Boosting Round 7, Residual RMSE: 2794.64\n  > Boosting Round 8, Residual RMSE: 2701.14\n  > Boosting Round 9, Residual RMSE: 2612.71\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2897.33\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 3, 'lr': 0.05, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2684.74\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 3, 'lr': 0.1, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3445.38\n  > Boosting Round 1, Residual RMSE: 3181.16\n  > Boosting Round 2, Residual RMSE: 2948.39\n  > Boosting Round 3, Residual RMSE: 2741.80\n  > Boosting Round 4, Residual RMSE: 2561.95\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2482.57\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3385.20\n  > Boosting Round 1, Residual RMSE: 3126.57\n  > Boosting Round 2, Residual RMSE: 2897.30\n  > Boosting Round 3, Residual RMSE: 2695.56\n  > Boosting Round 4, Residual RMSE: 2517.86\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2877.18\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3508.64\n  > Boosting Round 1, Residual RMSE: 3241.30\n  > Boosting Round 2, Residual RMSE: 3005.54\n  > Boosting Round 3, Residual RMSE: 2796.65\n  > Boosting Round 4, Residual RMSE: 2611.67\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2587.61\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3509.95\n  > Boosting Round 1, Residual RMSE: 3242.22\n  > Boosting Round 2, Residual RMSE: 3004.40\n  > Boosting Round 3, Residual RMSE: 2794.51\n  > Boosting Round 4, Residual RMSE: 2610.17\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2500.21\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3487.87\n  > Boosting Round 1, Residual RMSE: 3219.91\n  > Boosting Round 2, Residual RMSE: 2984.25\n  > Boosting Round 3, Residual RMSE: 2775.20\n  > Boosting Round 4, Residual RMSE: 2591.57\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2874.81\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 3, 'lr': 0.1, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 2664.48\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 3, 'lr': 0.1, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3445.38\n  > Boosting Round 1, Residual RMSE: 3181.16\n  > Boosting Round 2, Residual RMSE: 2948.39\n  > Boosting Round 3, Residual RMSE: 2741.80\n  > Boosting Round 4, Residual RMSE: 2561.95\n  > Boosting Round 5, Residual RMSE: 2403.09\n  > Boosting Round 6, Residual RMSE: 2264.73\n  > Boosting Round 7, Residual RMSE: 2144.22\n  > Boosting Round 8, Residual RMSE: 2037.37\n  > Boosting Round 9, Residual RMSE: 1945.98\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1880.39\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3385.20\n  > Boosting Round 1, Residual RMSE: 3126.57\n  > Boosting Round 2, Residual RMSE: 2897.30\n  > Boosting Round 3, Residual RMSE: 2695.56\n  > Boosting Round 4, Residual RMSE: 2517.86\n  > Boosting Round 5, Residual RMSE: 2360.94\n  > Boosting Round 6, Residual RMSE: 2223.28\n  > Boosting Round 7, Residual RMSE: 2103.95\n  > Boosting Round 8, Residual RMSE: 1998.45\n  > Boosting Round 9, Residual RMSE: 1907.12\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2249.69\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3508.64\n  > Boosting Round 1, Residual RMSE: 3241.30\n  > Boosting Round 2, Residual RMSE: 3005.54\n  > Boosting Round 3, Residual RMSE: 2796.65\n  > Boosting Round 4, Residual RMSE: 2611.67\n  > Boosting Round 5, Residual RMSE: 2451.29\n  > Boosting Round 6, Residual RMSE: 2309.51\n  > Boosting Round 7, Residual RMSE: 2186.06\n  > Boosting Round 8, Residual RMSE: 2079.77\n  > Boosting Round 9, Residual RMSE: 1985.56\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1933.72\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3509.95\n  > Boosting Round 1, Residual RMSE: 3242.22\n  > Boosting Round 2, Residual RMSE: 3004.40\n  > Boosting Round 3, Residual RMSE: 2794.51\n  > Boosting Round 4, Residual RMSE: 2610.17\n  > Boosting Round 5, Residual RMSE: 2446.41\n  > Boosting Round 6, Residual RMSE: 2305.69\n  > Boosting Round 7, Residual RMSE: 2181.23\n  > Boosting Round 8, Residual RMSE: 2071.04\n  > Boosting Round 9, Residual RMSE: 1977.14\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1875.64\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3487.87\n  > Boosting Round 1, Residual RMSE: 3219.91\n  > Boosting Round 2, Residual RMSE: 2984.25\n  > Boosting Round 3, Residual RMSE: 2775.20\n  > Boosting Round 4, Residual RMSE: 2591.57\n  > Boosting Round 5, Residual RMSE: 2429.10\n  > Boosting Round 6, Residual RMSE: 2289.12\n  > Boosting Round 7, Residual RMSE: 2165.47\n  > Boosting Round 8, Residual RMSE: 2055.90\n  > Boosting Round 9, Residual RMSE: 1961.78\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2224.04\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 3, 'lr': 0.1, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2032.70\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 4, 'lr': 0.05, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3586.61\n  > Boosting Round 1, Residual RMSE: 3436.68\n  > Boosting Round 2, Residual RMSE: 3295.86\n  > Boosting Round 3, Residual RMSE: 3162.09\n  > Boosting Round 4, Residual RMSE: 3036.62\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2924.30\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3523.07\n  > Boosting Round 1, Residual RMSE: 3376.43\n  > Boosting Round 2, Residual RMSE: 3237.83\n  > Boosting Round 3, Residual RMSE: 3107.58\n  > Boosting Round 4, Residual RMSE: 2984.47\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3360.32\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3651.47\n  > Boosting Round 1, Residual RMSE: 3500.42\n  > Boosting Round 2, Residual RMSE: 3357.52\n  > Boosting Round 3, Residual RMSE: 3223.25\n  > Boosting Round 4, Residual RMSE: 3096.23\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3090.34\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3653.84\n  > Boosting Round 1, Residual RMSE: 3502.13\n  > Boosting Round 2, Residual RMSE: 3359.05\n  > Boosting Round 3, Residual RMSE: 3223.89\n  > Boosting Round 4, Residual RMSE: 3095.74\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2983.94\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3631.03\n  > Boosting Round 1, Residual RMSE: 3480.03\n  > Boosting Round 2, Residual RMSE: 3337.43\n  > Boosting Round 3, Residual RMSE: 3201.25\n  > Boosting Round 4, Residual RMSE: 3073.92\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3370.11\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 4, 'lr': 0.05, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 3145.80\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 4, 'lr': 0.05, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3586.61\n  > Boosting Round 1, Residual RMSE: 3436.68\n  > Boosting Round 2, Residual RMSE: 3295.86\n  > Boosting Round 3, Residual RMSE: 3162.09\n  > Boosting Round 4, Residual RMSE: 3036.62\n  > Boosting Round 5, Residual RMSE: 2917.34\n  > Boosting Round 6, Residual RMSE: 2804.80\n  > Boosting Round 7, Residual RMSE: 2699.08\n  > Boosting Round 8, Residual RMSE: 2600.11\n  > Boosting Round 9, Residual RMSE: 2505.66\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2407.44\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3523.07\n  > Boosting Round 1, Residual RMSE: 3376.43\n  > Boosting Round 2, Residual RMSE: 3237.83\n  > Boosting Round 3, Residual RMSE: 3107.58\n  > Boosting Round 4, Residual RMSE: 2984.47\n  > Boosting Round 5, Residual RMSE: 2867.24\n  > Boosting Round 6, Residual RMSE: 2756.71\n  > Boosting Round 7, Residual RMSE: 2653.17\n  > Boosting Round 8, Residual RMSE: 2554.69\n  > Boosting Round 9, Residual RMSE: 2462.74\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2822.17\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3651.47\n  > Boosting Round 1, Residual RMSE: 3500.42\n  > Boosting Round 2, Residual RMSE: 3357.52\n  > Boosting Round 3, Residual RMSE: 3223.25\n  > Boosting Round 4, Residual RMSE: 3096.23\n  > Boosting Round 5, Residual RMSE: 2976.47\n  > Boosting Round 6, Residual RMSE: 2862.14\n  > Boosting Round 7, Residual RMSE: 2755.82\n  > Boosting Round 8, Residual RMSE: 2654.35\n  > Boosting Round 9, Residual RMSE: 2558.82\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2535.07\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3653.84\n  > Boosting Round 1, Residual RMSE: 3502.13\n  > Boosting Round 2, Residual RMSE: 3359.05\n  > Boosting Round 3, Residual RMSE: 3223.89\n  > Boosting Round 4, Residual RMSE: 3095.74\n  > Boosting Round 5, Residual RMSE: 2973.46\n  > Boosting Round 6, Residual RMSE: 2860.31\n  > Boosting Round 7, Residual RMSE: 2752.96\n  > Boosting Round 8, Residual RMSE: 2650.66\n  > Boosting Round 9, Residual RMSE: 2555.55\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2444.20\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3631.03\n  > Boosting Round 1, Residual RMSE: 3480.03\n  > Boosting Round 2, Residual RMSE: 3337.43\n  > Boosting Round 3, Residual RMSE: 3201.25\n  > Boosting Round 4, Residual RMSE: 3073.92\n  > Boosting Round 5, Residual RMSE: 2953.99\n  > Boosting Round 6, Residual RMSE: 2839.22\n  > Boosting Round 7, Residual RMSE: 2732.09\n  > Boosting Round 8, Residual RMSE: 2630.44\n  > Boosting Round 9, Residual RMSE: 2535.01\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2815.91\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 4, 'lr': 0.05, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2604.96\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 4, 'lr': 0.1, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3429.78\n  > Boosting Round 1, Residual RMSE: 3148.58\n  > Boosting Round 2, Residual RMSE: 2899.58\n  > Boosting Round 3, Residual RMSE: 2677.42\n  > Boosting Round 4, Residual RMSE: 2481.55\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2392.10\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3369.48\n  > Boosting Round 1, Residual RMSE: 3094.44\n  > Boosting Round 2, Residual RMSE: 2850.26\n  > Boosting Round 3, Residual RMSE: 2632.31\n  > Boosting Round 4, Residual RMSE: 2439.66\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2800.69\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3492.73\n  > Boosting Round 1, Residual RMSE: 3209.18\n  > Boosting Round 2, Residual RMSE: 2958.17\n  > Boosting Round 3, Residual RMSE: 2732.60\n  > Boosting Round 4, Residual RMSE: 2535.68\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2512.84\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3494.33\n  > Boosting Round 1, Residual RMSE: 3209.29\n  > Boosting Round 2, Residual RMSE: 2953.35\n  > Boosting Round 3, Residual RMSE: 2730.42\n  > Boosting Round 4, Residual RMSE: 2531.75\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2421.88\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3472.54\n  > Boosting Round 1, Residual RMSE: 3189.83\n  > Boosting Round 2, Residual RMSE: 2934.68\n  > Boosting Round 3, Residual RMSE: 2710.01\n  > Boosting Round 4, Residual RMSE: 2512.22\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2793.76\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 4, 'lr': 0.1, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 2584.25\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 4, 'lr': 0.1, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3429.78\n  > Boosting Round 1, Residual RMSE: 3148.58\n  > Boosting Round 2, Residual RMSE: 2899.58\n  > Boosting Round 3, Residual RMSE: 2677.42\n  > Boosting Round 4, Residual RMSE: 2481.55\n  > Boosting Round 5, Residual RMSE: 2308.65\n  > Boosting Round 6, Residual RMSE: 2155.13\n  > Boosting Round 7, Residual RMSE: 2018.75\n  > Boosting Round 8, Residual RMSE: 1900.28\n  > Boosting Round 9, Residual RMSE: 1796.65\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1722.91\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3369.48\n  > Boosting Round 1, Residual RMSE: 3094.44\n  > Boosting Round 2, Residual RMSE: 2850.26\n  > Boosting Round 3, Residual RMSE: 2632.31\n  > Boosting Round 4, Residual RMSE: 2439.66\n  > Boosting Round 5, Residual RMSE: 2267.90\n  > Boosting Round 6, Residual RMSE: 2116.55\n  > Boosting Round 7, Residual RMSE: 1984.88\n  > Boosting Round 8, Residual RMSE: 1868.20\n  > Boosting Round 9, Residual RMSE: 1766.37\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2114.40\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3492.73\n  > Boosting Round 1, Residual RMSE: 3209.18\n  > Boosting Round 2, Residual RMSE: 2958.17\n  > Boosting Round 3, Residual RMSE: 2732.60\n  > Boosting Round 4, Residual RMSE: 2535.68\n  > Boosting Round 5, Residual RMSE: 2359.91\n  > Boosting Round 6, Residual RMSE: 2204.94\n  > Boosting Round 7, Residual RMSE: 2069.47\n  > Boosting Round 8, Residual RMSE: 1949.03\n  > Boosting Round 9, Residual RMSE: 1843.84\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1792.06\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3494.33\n  > Boosting Round 1, Residual RMSE: 3209.29\n  > Boosting Round 2, Residual RMSE: 2953.35\n  > Boosting Round 3, Residual RMSE: 2730.42\n  > Boosting Round 4, Residual RMSE: 2531.75\n  > Boosting Round 5, Residual RMSE: 2356.59\n  > Boosting Round 6, Residual RMSE: 2199.97\n  > Boosting Round 7, Residual RMSE: 2062.97\n  > Boosting Round 8, Residual RMSE: 1944.91\n  > Boosting Round 9, Residual RMSE: 1837.09\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1724.04\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3472.54\n  > Boosting Round 1, Residual RMSE: 3189.83\n  > Boosting Round 2, Residual RMSE: 2934.68\n  > Boosting Round 3, Residual RMSE: 2710.01\n  > Boosting Round 4, Residual RMSE: 2512.22\n  > Boosting Round 5, Residual RMSE: 2336.11\n  > Boosting Round 6, Residual RMSE: 2180.26\n  > Boosting Round 7, Residual RMSE: 2043.65\n  > Boosting Round 8, Residual RMSE: 1924.24\n  > Boosting Round 9, Residual RMSE: 1819.19\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2068.93\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 4, 'lr': 0.1, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 1884.47\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 5, 'lr': 0.05, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3580.20\n  > Boosting Round 1, Residual RMSE: 3424.19\n  > Boosting Round 2, Residual RMSE: 3277.56\n  > Boosting Round 3, Residual RMSE: 3138.40\n  > Boosting Round 4, Residual RMSE: 3006.33\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2891.51\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3516.78\n  > Boosting Round 1, Residual RMSE: 3364.52\n  > Boosting Round 2, Residual RMSE: 3220.55\n  > Boosting Round 3, Residual RMSE: 3084.19\n  > Boosting Round 4, Residual RMSE: 2955.83\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3332.21\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3645.68\n  > Boosting Round 1, Residual RMSE: 3489.10\n  > Boosting Round 2, Residual RMSE: 3340.73\n  > Boosting Round 3, Residual RMSE: 3201.47\n  > Boosting Round 4, Residual RMSE: 3068.41\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3063.31\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3648.17\n  > Boosting Round 1, Residual RMSE: 3491.04\n  > Boosting Round 2, Residual RMSE: 3342.52\n  > Boosting Round 3, Residual RMSE: 3201.70\n  > Boosting Round 4, Residual RMSE: 3067.30\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2954.02\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3624.96\n  > Boosting Round 1, Residual RMSE: 3467.91\n  > Boosting Round 2, Residual RMSE: 3320.00\n  > Boosting Round 3, Residual RMSE: 3179.72\n  > Boosting Round 4, Residual RMSE: 3046.08\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3339.51\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 5, 'lr': 0.05, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 3116.11\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 5, 'lr': 0.05, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3580.20\n  > Boosting Round 1, Residual RMSE: 3424.19\n  > Boosting Round 2, Residual RMSE: 3277.56\n  > Boosting Round 3, Residual RMSE: 3138.40\n  > Boosting Round 4, Residual RMSE: 3006.33\n  > Boosting Round 5, Residual RMSE: 2881.74\n  > Boosting Round 6, Residual RMSE: 2764.24\n  > Boosting Round 7, Residual RMSE: 2652.71\n  > Boosting Round 8, Residual RMSE: 2547.00\n  > Boosting Round 9, Residual RMSE: 2448.10\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2348.75\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3516.78\n  > Boosting Round 1, Residual RMSE: 3364.52\n  > Boosting Round 2, Residual RMSE: 3220.55\n  > Boosting Round 3, Residual RMSE: 3084.19\n  > Boosting Round 4, Residual RMSE: 2955.83\n  > Boosting Round 5, Residual RMSE: 2833.91\n  > Boosting Round 6, Residual RMSE: 2717.96\n  > Boosting Round 7, Residual RMSE: 2609.59\n  > Boosting Round 8, Residual RMSE: 2506.10\n  > Boosting Round 9, Residual RMSE: 2408.83\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2775.65\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3645.68\n  > Boosting Round 1, Residual RMSE: 3489.10\n  > Boosting Round 2, Residual RMSE: 3340.73\n  > Boosting Round 3, Residual RMSE: 3201.47\n  > Boosting Round 4, Residual RMSE: 3068.41\n  > Boosting Round 5, Residual RMSE: 2943.77\n  > Boosting Round 6, Residual RMSE: 2824.08\n  > Boosting Round 7, Residual RMSE: 2711.58\n  > Boosting Round 8, Residual RMSE: 2606.46\n  > Boosting Round 9, Residual RMSE: 2506.51\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2484.43\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3648.17\n  > Boosting Round 1, Residual RMSE: 3491.04\n  > Boosting Round 2, Residual RMSE: 3342.52\n  > Boosting Round 3, Residual RMSE: 3201.70\n  > Boosting Round 4, Residual RMSE: 3067.30\n  > Boosting Round 5, Residual RMSE: 2941.91\n  > Boosting Round 6, Residual RMSE: 2822.32\n  > Boosting Round 7, Residual RMSE: 2709.08\n  > Boosting Round 8, Residual RMSE: 2603.47\n  > Boosting Round 9, Residual RMSE: 2502.97\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2391.38\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3624.96\n  > Boosting Round 1, Residual RMSE: 3467.91\n  > Boosting Round 2, Residual RMSE: 3320.00\n  > Boosting Round 3, Residual RMSE: 3179.72\n  > Boosting Round 4, Residual RMSE: 3046.08\n  > Boosting Round 5, Residual RMSE: 2921.00\n  > Boosting Round 6, Residual RMSE: 2801.81\n  > Boosting Round 7, Residual RMSE: 2689.48\n  > Boosting Round 8, Residual RMSE: 2583.24\n  > Boosting Round 9, Residual RMSE: 2482.29\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2762.40\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 5, 'lr': 0.05, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2552.52\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 5, 'lr': 0.1, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3416.71\n  > Boosting Round 1, Residual RMSE: 3124.19\n  > Boosting Round 2, Residual RMSE: 2862.16\n  > Boosting Round 3, Residual RMSE: 2631.17\n  > Boosting Round 4, Residual RMSE: 2423.72\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2322.07\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3356.65\n  > Boosting Round 1, Residual RMSE: 3071.27\n  > Boosting Round 2, Residual RMSE: 2815.52\n  > Boosting Round 3, Residual RMSE: 2586.59\n  > Boosting Round 4, Residual RMSE: 2384.40\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2745.44\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3480.92\n  > Boosting Round 1, Residual RMSE: 3186.38\n  > Boosting Round 2, Residual RMSE: 2922.96\n  > Boosting Round 3, Residual RMSE: 2687.46\n  > Boosting Round 4, Residual RMSE: 2480.70\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2457.43\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3482.78\n  > Boosting Round 1, Residual RMSE: 3188.28\n  > Boosting Round 2, Residual RMSE: 2921.65\n  > Boosting Round 3, Residual RMSE: 2688.39\n  > Boosting Round 4, Residual RMSE: 2477.94\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2365.07\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3460.16\n  > Boosting Round 1, Residual RMSE: 3166.32\n  > Boosting Round 2, Residual RMSE: 2903.90\n  > Boosting Round 3, Residual RMSE: 2667.26\n  > Boosting Round 4, Residual RMSE: 2457.28\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2734.57\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 5, 'lr': 0.1, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 2524.92\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 5, 'lr': 0.1, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3416.71\n  > Boosting Round 1, Residual RMSE: 3124.19\n  > Boosting Round 2, Residual RMSE: 2862.16\n  > Boosting Round 3, Residual RMSE: 2631.17\n  > Boosting Round 4, Residual RMSE: 2423.72\n  > Boosting Round 5, Residual RMSE: 2239.50\n  > Boosting Round 6, Residual RMSE: 2075.74\n  > Boosting Round 7, Residual RMSE: 1932.56\n  > Boosting Round 8, Residual RMSE: 1805.36\n  > Boosting Round 9, Residual RMSE: 1690.21\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1616.91\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3356.65\n  > Boosting Round 1, Residual RMSE: 3071.27\n  > Boosting Round 2, Residual RMSE: 2815.52\n  > Boosting Round 3, Residual RMSE: 2586.59\n  > Boosting Round 4, Residual RMSE: 2384.40\n  > Boosting Round 5, Residual RMSE: 2203.51\n  > Boosting Round 6, Residual RMSE: 2041.89\n  > Boosting Round 7, Residual RMSE: 1900.38\n  > Boosting Round 8, Residual RMSE: 1774.04\n  > Boosting Round 9, Residual RMSE: 1662.76\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2031.08\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3480.92\n  > Boosting Round 1, Residual RMSE: 3186.38\n  > Boosting Round 2, Residual RMSE: 2922.96\n  > Boosting Round 3, Residual RMSE: 2687.46\n  > Boosting Round 4, Residual RMSE: 2480.70\n  > Boosting Round 5, Residual RMSE: 2294.97\n  > Boosting Round 6, Residual RMSE: 2128.79\n  > Boosting Round 7, Residual RMSE: 1984.43\n  > Boosting Round 8, Residual RMSE: 1856.20\n  > Boosting Round 9, Residual RMSE: 1741.79\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1689.36\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3482.78\n  > Boosting Round 1, Residual RMSE: 3188.28\n  > Boosting Round 2, Residual RMSE: 2921.65\n  > Boosting Round 3, Residual RMSE: 2688.39\n  > Boosting Round 4, Residual RMSE: 2477.94\n  > Boosting Round 5, Residual RMSE: 2292.36\n  > Boosting Round 6, Residual RMSE: 2127.43\n  > Boosting Round 7, Residual RMSE: 1982.00\n  > Boosting Round 8, Residual RMSE: 1851.62\n  > Boosting Round 9, Residual RMSE: 1739.48\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1624.35\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3460.16\n  > Boosting Round 1, Residual RMSE: 3166.32\n  > Boosting Round 2, Residual RMSE: 2903.90\n  > Boosting Round 3, Residual RMSE: 2667.26\n  > Boosting Round 4, Residual RMSE: 2457.28\n  > Boosting Round 5, Residual RMSE: 2273.64\n  > Boosting Round 6, Residual RMSE: 2108.67\n  > Boosting Round 7, Residual RMSE: 1964.37\n  > Boosting Round 8, Residual RMSE: 1834.50\n  > Boosting Round 9, Residual RMSE: 1718.96\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1967.18\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 5, 'lr': 0.1, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 1785.78\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 10, 'lr': 0.05, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3565.42\n  > Boosting Round 1, Residual RMSE: 3395.32\n  > Boosting Round 2, Residual RMSE: 3233.90\n  > Boosting Round 3, Residual RMSE: 3080.72\n  > Boosting Round 4, Residual RMSE: 2935.30\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2823.43\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3502.80\n  > Boosting Round 1, Residual RMSE: 3336.70\n  > Boosting Round 2, Residual RMSE: 3179.24\n  > Boosting Round 3, Residual RMSE: 3029.95\n  > Boosting Round 4, Residual RMSE: 2888.27\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3268.32\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3630.55\n  > Boosting Round 1, Residual RMSE: 3458.99\n  > Boosting Round 2, Residual RMSE: 3296.41\n  > Boosting Round 3, Residual RMSE: 3142.18\n  > Boosting Round 4, Residual RMSE: 2996.02\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2998.19\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3633.37\n  > Boosting Round 1, Residual RMSE: 3461.42\n  > Boosting Round 2, Residual RMSE: 3298.41\n  > Boosting Round 3, Residual RMSE: 3144.03\n  > Boosting Round 4, Residual RMSE: 2997.53\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2901.90\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3610.94\n  > Boosting Round 1, Residual RMSE: 3440.28\n  > Boosting Round 2, Residual RMSE: 3278.22\n  > Boosting Round 3, Residual RMSE: 3124.78\n  > Boosting Round 4, Residual RMSE: 2978.86\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 3260.23\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 10, 'lr': 0.05, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 3050.41\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 10, 'lr': 0.05, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3565.42\n  > Boosting Round 1, Residual RMSE: 3395.32\n  > Boosting Round 2, Residual RMSE: 3233.90\n  > Boosting Round 3, Residual RMSE: 3080.72\n  > Boosting Round 4, Residual RMSE: 2935.30\n  > Boosting Round 5, Residual RMSE: 2797.29\n  > Boosting Round 6, Residual RMSE: 2666.49\n  > Boosting Round 7, Residual RMSE: 2542.22\n  > Boosting Round 8, Residual RMSE: 2424.34\n  > Boosting Round 9, Residual RMSE: 2312.29\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2222.53\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3502.80\n  > Boosting Round 1, Residual RMSE: 3336.70\n  > Boosting Round 2, Residual RMSE: 3179.24\n  > Boosting Round 3, Residual RMSE: 3029.95\n  > Boosting Round 4, Residual RMSE: 2888.27\n  > Boosting Round 5, Residual RMSE: 2753.43\n  > Boosting Round 6, Residual RMSE: 2625.21\n  > Boosting Round 7, Residual RMSE: 2503.77\n  > Boosting Round 8, Residual RMSE: 2388.39\n  > Boosting Round 9, Residual RMSE: 2279.31\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2654.14\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3630.55\n  > Boosting Round 1, Residual RMSE: 3458.99\n  > Boosting Round 2, Residual RMSE: 3296.41\n  > Boosting Round 3, Residual RMSE: 3142.18\n  > Boosting Round 4, Residual RMSE: 2996.02\n  > Boosting Round 5, Residual RMSE: 2857.06\n  > Boosting Round 6, Residual RMSE: 2725.31\n  > Boosting Round 7, Residual RMSE: 2600.47\n  > Boosting Round 8, Residual RMSE: 2482.01\n  > Boosting Round 9, Residual RMSE: 2369.74\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2364.06\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3633.37\n  > Boosting Round 1, Residual RMSE: 3461.42\n  > Boosting Round 2, Residual RMSE: 3298.41\n  > Boosting Round 3, Residual RMSE: 3144.03\n  > Boosting Round 4, Residual RMSE: 2997.53\n  > Boosting Round 5, Residual RMSE: 2858.63\n  > Boosting Round 6, Residual RMSE: 2726.22\n  > Boosting Round 7, Residual RMSE: 2601.45\n  > Boosting Round 8, Residual RMSE: 2482.68\n  > Boosting Round 9, Residual RMSE: 2370.41\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2291.96\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3610.94\n  > Boosting Round 1, Residual RMSE: 3440.28\n  > Boosting Round 2, Residual RMSE: 3278.22\n  > Boosting Round 3, Residual RMSE: 3124.78\n  > Boosting Round 4, Residual RMSE: 2978.86\n  > Boosting Round 5, Residual RMSE: 2840.72\n  > Boosting Round 6, Residual RMSE: 2709.67\n  > Boosting Round 7, Residual RMSE: 2585.11\n  > Boosting Round 8, Residual RMSE: 2467.24\n  > Boosting Round 9, Residual RMSE: 2354.82\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2611.14\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 10, 'lr': 0.05, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 2428.77\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 5}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3386.45\n  > Boosting Round 1, Residual RMSE: 3064.90\n  > Boosting Round 2, Residual RMSE: 2775.94\n  > Boosting Round 3, Residual RMSE: 2517.02\n  > Boosting Round 4, Residual RMSE: 2283.90\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2195.47\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3328.04\n  > Boosting Round 1, Residual RMSE: 3014.47\n  > Boosting Round 2, Residual RMSE: 2733.08\n  > Boosting Round 3, Residual RMSE: 2479.25\n  > Boosting Round 4, Residual RMSE: 2251.42\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2622.78\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3449.98\n  > Boosting Round 1, Residual RMSE: 3126.13\n  > Boosting Round 2, Residual RMSE: 2836.00\n  > Boosting Round 3, Residual RMSE: 2574.91\n  > Boosting Round 4, Residual RMSE: 2341.19\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2334.14\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3452.48\n  > Boosting Round 1, Residual RMSE: 3127.78\n  > Boosting Round 2, Residual RMSE: 2837.11\n  > Boosting Round 3, Residual RMSE: 2575.46\n  > Boosting Round 4, Residual RMSE: 2341.55\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2263.90\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3431.47\n  > Boosting Round 1, Residual RMSE: 3108.83\n  > Boosting Round 2, Residual RMSE: 2819.13\n  > Boosting Round 3, Residual RMSE: 2559.40\n  > Boosting Round 4, Residual RMSE: 2326.96\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 2581.04\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 5}\n========================================\nAverage Custom GBDT RMSE: 2399.47\n========================================\n\n############################################################\nTESTING CONFIGURATION: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 10}\n############################################################\nStarting Store-Aware Temporal Cross-Validation...\n\n--- FOLD 1 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3386.45\n  > Boosting Round 1, Residual RMSE: 3064.90\n  > Boosting Round 2, Residual RMSE: 2775.94\n  > Boosting Round 3, Residual RMSE: 2517.02\n  > Boosting Round 4, Residual RMSE: 2283.90\n  > Boosting Round 5, Residual RMSE: 2074.62\n  > Boosting Round 6, Residual RMSE: 1885.43\n  > Boosting Round 7, Residual RMSE: 1716.89\n  > Boosting Round 8, Residual RMSE: 1565.63\n  > Boosting Round 9, Residual RMSE: 1430.52\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1385.95\n\n--- FOLD 2 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3328.04\n  > Boosting Round 1, Residual RMSE: 3014.47\n  > Boosting Round 2, Residual RMSE: 2733.08\n  > Boosting Round 3, Residual RMSE: 2479.25\n  > Boosting Round 4, Residual RMSE: 2251.42\n  > Boosting Round 5, Residual RMSE: 2047.48\n  > Boosting Round 6, Residual RMSE: 1865.08\n  > Boosting Round 7, Residual RMSE: 1701.74\n  > Boosting Round 8, Residual RMSE: 1555.11\n  > Boosting Round 9, Residual RMSE: 1424.33\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1798.44\n\n--- FOLD 3 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3449.98\n  > Boosting Round 1, Residual RMSE: 3126.13\n  > Boosting Round 2, Residual RMSE: 2836.00\n  > Boosting Round 3, Residual RMSE: 2574.91\n  > Boosting Round 4, Residual RMSE: 2341.19\n  > Boosting Round 5, Residual RMSE: 2129.95\n  > Boosting Round 6, Residual RMSE: 1941.24\n  > Boosting Round 7, Residual RMSE: 1772.70\n  > Boosting Round 8, Residual RMSE: 1621.46\n  > Boosting Round 9, Residual RMSE: 1485.78\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1467.12\n\n--- FOLD 4 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3452.48\n  > Boosting Round 1, Residual RMSE: 3127.78\n  > Boosting Round 2, Residual RMSE: 2837.11\n  > Boosting Round 3, Residual RMSE: 2575.46\n  > Boosting Round 4, Residual RMSE: 2341.55\n  > Boosting Round 5, Residual RMSE: 2131.75\n  > Boosting Round 6, Residual RMSE: 1942.34\n  > Boosting Round 7, Residual RMSE: 1772.64\n  > Boosting Round 8, Residual RMSE: 1621.93\n  > Boosting Round 9, Residual RMSE: 1486.42\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1430.33\n\n--- FOLD 5 / 5 ---\n  > Boosting Round 0, Residual RMSE: 3431.47\n  > Boosting Round 1, Residual RMSE: 3108.83\n  > Boosting Round 2, Residual RMSE: 2819.13\n  > Boosting Round 3, Residual RMSE: 2559.40\n  > Boosting Round 4, Residual RMSE: 2326.96\n  > Boosting Round 5, Residual RMSE: 2117.21\n  > Boosting Round 6, Residual RMSE: 1929.88\n  > Boosting Round 7, Residual RMSE: 1762.23\n  > Boosting Round 8, Residual RMSE: 1612.33\n  > Boosting Round 9, Residual RMSE: 1478.45\nFold Results -> LR RMSE: 4593.55 | GBDT RMSE: 1696.51\n\n========================================\nSUMMARY FOR CONFIG: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 10}\n========================================\nAverage Custom GBDT RMSE: 1555.67\n========================================\n\n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nGRID SEARCH COMPLETE\nBEST CONFIGURATION For gdb: {'max_depth': 10, 'lr': 0.1, 'n_estimators': 10}\nLOWEST AVERAGE CV RMSE: 1555.67\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#now, we train a model using the best hyperparameters that we found and test it using the test dataset\n# 1. Force all columns to numeric and cast the final array to float32\ntest_df = pd.read_csv(\"test_split.csv\")\nX_train_numeric = df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\nX_test_numeric = test_df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n# 2. Now convert the pure float32 array to a Tensor\nX_train = torch.tensor(X_train_numeric, device=device)\ny_train = torch.tensor(df['Sales'].values.astype(np.float32), device=device)\n\nX_test = torch.tensor(X_test_numeric, device=device)\ny_test = torch.tensor(test_df['Sales'].values.astype(np.float32), device=device)\n\n# Train Custom GBDT (Using best parameters)\ngbdt_model = GBDTScratch(n_estimators=best_config[\"n_estimators\"], max_depth=best_config[\"max_depth\"], lr=best_config[\"lr\"])\ngbdt_model.fit(X_train, y_train)\ngbdt_rmse = get_rmse(y_test, gbdt_model.predict(X_test))\n\nprint(f\"final gbdt rmse = {gbdt_rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T18:04:28.531221Z","iopub.execute_input":"2026-02-21T18:04:28.531621Z","iopub.status.idle":"2026-02-21T18:17:11.043070Z","shell.execute_reply.started":"2026-02-21T18:04:28.531597Z","shell.execute_reply":"2026-02-21T18:17:11.042225Z"}},"outputs":[{"name":"stdout","text":"  > Boosting Round 0, Residual RMSE: 3480.38\n  > Boosting Round 1, Residual RMSE: 3154.15\n  > Boosting Round 2, Residual RMSE: 2859.98\n  > Boosting Round 3, Residual RMSE: 2597.37\n  > Boosting Round 4, Residual RMSE: 2360.59\n  > Boosting Round 5, Residual RMSE: 2148.15\n  > Boosting Round 6, Residual RMSE: 1957.33\n  > Boosting Round 7, Residual RMSE: 1786.41\n  > Boosting Round 8, Residual RMSE: 1634.55\n  > Boosting Round 9, Residual RMSE: 1498.38\nfinal gbdt rmse = 1549.60595703125\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#now, we increase the number of estimators to 50\n# 1. Force all columns to numeric and cast the final array to float32\ntest_df = pd.read_csv(\"test_split.csv\")\nX_train_numeric = df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\nX_test_numeric = test_df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n# 2. Now convert the pure float32 array to a Tensor\nX_train = torch.tensor(X_train_numeric, device=device)\ny_train = torch.tensor(df['Sales'].values.astype(np.float32), device=device)\n\nX_test = torch.tensor(X_test_numeric, device=device)\ny_test = torch.tensor(test_df['Sales'].values.astype(np.float32), device=device)\n\n# Train Custom GBDT\ngbdt_model = GBDTScratch(n_estimators=50, max_depth=10, lr=0.1)\ngbdt_model.fit(X_train, y_train)\ngbdt_rmse = get_rmse(y_test, gbdt_model.predict(X_test))\n\nprint(f\"final gbdt test rmse = {gbdt_rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T18:17:35.909752Z","iopub.execute_input":"2026-02-21T18:17:35.910101Z","iopub.status.idle":"2026-02-21T19:20:24.264537Z","shell.execute_reply.started":"2026-02-21T18:17:35.910075Z","shell.execute_reply":"2026-02-21T19:20:24.263698Z"}},"outputs":[{"name":"stdout","text":"  > Boosting Round 0, Residual RMSE: 3480.38\n  > Boosting Round 1, Residual RMSE: 3154.15\n  > Boosting Round 2, Residual RMSE: 2859.98\n  > Boosting Round 3, Residual RMSE: 2597.37\n  > Boosting Round 4, Residual RMSE: 2360.59\n  > Boosting Round 5, Residual RMSE: 2148.15\n  > Boosting Round 6, Residual RMSE: 1957.33\n  > Boosting Round 7, Residual RMSE: 1786.41\n  > Boosting Round 8, Residual RMSE: 1634.55\n  > Boosting Round 9, Residual RMSE: 1498.38\n  > Boosting Round 10, Residual RMSE: 1377.09\n  > Boosting Round 11, Residual RMSE: 1268.68\n  > Boosting Round 12, Residual RMSE: 1171.19\n  > Boosting Round 13, Residual RMSE: 1084.26\n  > Boosting Round 14, Residual RMSE: 1008.35\n  > Boosting Round 15, Residual RMSE: 940.88\n  > Boosting Round 16, Residual RMSE: 880.84\n  > Boosting Round 17, Residual RMSE: 827.75\n  > Boosting Round 18, Residual RMSE: 780.64\n  > Boosting Round 19, Residual RMSE: 739.81\n  > Boosting Round 20, Residual RMSE: 704.20\n  > Boosting Round 21, Residual RMSE: 673.02\n  > Boosting Round 22, Residual RMSE: 645.19\n  > Boosting Round 23, Residual RMSE: 622.03\n  > Boosting Round 24, Residual RMSE: 601.53\n  > Boosting Round 25, Residual RMSE: 583.23\n  > Boosting Round 26, Residual RMSE: 567.25\n  > Boosting Round 27, Residual RMSE: 552.80\n  > Boosting Round 28, Residual RMSE: 540.63\n  > Boosting Round 29, Residual RMSE: 530.32\n  > Boosting Round 30, Residual RMSE: 520.53\n  > Boosting Round 31, Residual RMSE: 512.70\n  > Boosting Round 32, Residual RMSE: 504.47\n  > Boosting Round 33, Residual RMSE: 497.89\n  > Boosting Round 34, Residual RMSE: 492.21\n  > Boosting Round 35, Residual RMSE: 486.44\n  > Boosting Round 36, Residual RMSE: 481.31\n  > Boosting Round 37, Residual RMSE: 476.76\n  > Boosting Round 38, Residual RMSE: 472.52\n  > Boosting Round 39, Residual RMSE: 468.60\n  > Boosting Round 40, Residual RMSE: 464.62\n  > Boosting Round 41, Residual RMSE: 461.48\n  > Boosting Round 42, Residual RMSE: 458.28\n  > Boosting Round 43, Residual RMSE: 455.07\n  > Boosting Round 44, Residual RMSE: 451.66\n  > Boosting Round 45, Residual RMSE: 448.51\n  > Boosting Round 46, Residual RMSE: 445.73\n  > Boosting Round 47, Residual RMSE: 443.50\n  > Boosting Round 48, Residual RMSE: 441.29\n  > Boosting Round 49, Residual RMSE: 439.09\nfinal gbdt test rmse = 492.7620849609375\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#training and testing the base line\n# 1. Force all columns to numeric and cast the final array to float32\ntest_df = pd.read_csv(\"test_split.csv\")\nX_train_numeric = df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\nX_test_numeric = test_df[features].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)\n\n# 2. Now convert the pure float32 array to a Tensor\nX_train = torch.tensor(X_train_numeric, device=device)\ny_train = torch.tensor(df['Sales'].values.astype(np.float32), device=device)\n\nX_test = torch.tensor(X_test_numeric, device=device)\ny_test = torch.tensor(test_df['Sales'].values.astype(np.float32), device=device)\n# Train Scratch Linear Regression\nlr_model = LinearRegressionScratch()\nlr_model.fit(X_train, y_train)\nlr_rmse = get_rmse(y_test, lr_model.predict(X_test))\nprint(f\"final base line (regression) test rmse = {lr_rmse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T19:21:18.892121Z","iopub.execute_input":"2026-02-21T19:21:18.892449Z","iopub.status.idle":"2026-02-21T19:21:35.780878Z","shell.execute_reply.started":"2026-02-21T19:21:18.892426Z","shell.execute_reply":"2026-02-21T19:21:35.779956Z"}},"outputs":[{"name":"stdout","text":"final base line (regression) test rmse = 4191.68212890625\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"torch.save(gbdt_model, \"gbdt_model.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T19:20:41.050762Z","iopub.execute_input":"2026-02-21T19:20:41.051064Z","iopub.status.idle":"2026-02-21T19:20:48.485038Z","shell.execute_reply.started":"2026-02-21T19:20:41.051043Z","shell.execute_reply":"2026-02-21T19:20:48.484105Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}